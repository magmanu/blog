"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7754],{1654:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"matrices-github-actions","metadata":{"permalink":"/blog/pt-BR/tech/matrices-github-actions","source":"@site/tech/2025-03-28-matrices-github-actions/index.mdx","title":"An Ultimate Guide to Matrices in GitHub Actions, from Basic to Advanced","description":"Listen, I feel the boldest of girls for calling this *an* ultimate guide. But it\'s just because this will be the one post about matrices I\'ll update over time as I experience more. All info in a single place for easier retrieval, enjoy!","date":"2025-03-28T00:00:00.000Z","tags":[{"label":"github actions","permalink":"/blog/pt-BR/tech/tags/github-actions"},{"label":"ci/cd","permalink":"/blog/pt-BR/tech/tags/ci-cd"},{"label":"devops","permalink":"/blog/pt-BR/tech/tags/devops"}],"readingTime":17.52,"hasTruncateMarker":true,"authors":[{"name":"Manu Magalh\xe3es","title":"Engenheira de DevSecOps","url":"https://github.com/magmanu","imageURL":"https://github.com/magmanu.png","key":"manu"}],"frontMatter":{"slug":"matrices-github-actions","title":"An Ultimate Guide to Matrices in GitHub Actions, from Basic to Advanced","authors":"manu","tags":["github actions","ci/cd","devops"]},"unlisted":false,"nextItem":{"title":"GitHub Actions: Fluxo e Persist\xeancia de Dados em Workflows","permalink":"/blog/pt-BR/tech/github-actions-data-flow"}},"content":"_Listen, I feel the boldest of girls for calling this *an* ultimate guide. But it\'s just because this will be the one post about matrices I\'ll update over time as I experience more. All info in a single place for easier retrieval, enjoy!_\\n\\nMatrices keep workflows DRY: you setup a job once and let the matrix do the boring work of multiplying it with all the different configurations required.  \\n\\n<h3>An Ultimate Guide</h3>\\n\\nimport TOCInline from \'@theme/TOCInline\';\\n\\n<TOCInline toc={toc} />\\n\\n## Basics: Simple Matrix\\n\\nUse a matrix to run the same job multiple times, with different configurations.  \\n\\nMatrices are set at the job level, under the `strategy` key. Then, at the step level, reference the matrix values with `${{ matrix.key_name}}`.\\n\\nLet\'s follow the classic workflow example, of course: running CI tests in different versions of Node.js.\\n\\n<details>\\n<summary>\\n  Show code\\n</summary>\\n<div>\\n\\n```yaml title=\\".github/workflows/testing.yaml\\" showLineNumbers\\n(...)\\njobs:\\n  unit-tests:\\n    // highlight-start\\n    strategy:\\n      matrix:\\n        # I named it `node-version`, but you can name it however you want\\n        node-version: [16, 18] \\n    // highlight-end\\n    runs-on: ubuntu-latest\\n    steps:\\n      - name: Checkout\\n        (...)\\n\\n      // highlight-start\\n      # And to reference it, use `${{ matrix.key_name}}`\\n      - name: Use Node.js ${{ matrix.node-version }}\\n      // highlight-end\\n        uses: actions/setup-node@v4\\n        with:\\n        // highlight-next-line\\n          node-version: ${{ matrix.node-version }}\\n\\n      (...)\\n  ```\\n\\n</div>\\n</details>\\n\\n\\n<details>\\n<summary>\\n  Show pipeline\\n</summary>\\n<div>\\n\\n![screenshot](./screenshot_13.png)\\n</div>\\n</details>\\n\\n## Multidimensional Matrices (Matrix with Multiple Keys)\\n\\nOf course this can get more complex. If you want to run your tests in Node.js 16 & 18, **and** test each node version in a different OS, you can use a matrix with multiple keys (aka matrix of matrices, or multidimensional matrices).\\n\\nPlease note: in a matrix of matrices, the number of jobs is the product of the matrix sizes - that is, the number of items in matrix A multiplied by the number of items in matrix B. \\n\\nSo if we specify two node versions and two OSs, like this...\\n\\n```yaml title=\\".github/workflows/testing.yaml\\" showLineNumbers\\nmatrix:\\n  os: [ubuntu-latest, windows-latest]\\n  node-version: [16, 18]\\n```\\n\\n... we\'ll end up with 4 jobs (2*2):\\n\\n- ubuntu-latest + node 16\\n- ubuntu-latest + node 18\\n- windows-latest + node 16\\n- windows-latest + node 18\\n\\n<details>\\n<summary>\\n  Show code\\n</summary>\\n\\n<div>\\n\\n```yaml title=\\".github/workflows/testing.yaml\\" showLineNumbers\\n(...)\\n  unit-tests:\\n    strategy:\\n      matrix:\\n      // highlight-start\\n        os: [ubuntu-latest, windows-latest]\\n        node-version: [16, 18]\\n    runs-on: ${{ matrix.os }}\\n    // highlight-end\\n    steps:\\n      - name: Checkout\\n        (...)\\n\\n      // highlight-next-line\\n      - name: Use Node.js ${{ matrix.node-version }} in ${{ matrix.os }}\\n        uses: actions/setup-node@v2\\n        with:\\n          node-version: ${{ matrix.node-version }}\\n\\n      (...)\\n  ```\\n\\n</div>\\n</details>\\n\\n<details>\\n<summary>\\n  Show pipeline\\n</summary>\\n<div>\\n\\n![screenshot](./screenshot_14.png)\\n</div>\\n</details>\\n\\nYou can have as many keys you want, but keep in mind that the number of jobs **can grow exponentially**. For example, if you have 4 matrices keys with 3 values each, you\'ll end up with 81 jobs (3\\\\*3\\\\*3\\\\*3).\\n\\n\x3c!--truncate--\x3e\\n\\n## Adjusting matrices with `include` & `exclude`, part I: the \\"odd job\\"\\n\\n### Static usage\\nIf you know beforehand all the matrix values you\'ll use, you can set them statically.  \\n\\nLet\'s say your team will also run tests for Node.js 18 in Windows machines. There are two ways to handle this:\\n\\n#### `include`\\nWith `include`, you can **add** an \\"odd value\\" to your matrix.  \\nBelow, we\'ll write a matrix for combinations between the Ubuntu OS and two Node.js versions, and use `include` to add the odd `windows-latest` + Node.js `18` combination.\\n\\n<details>\\n<summary>\\n  Show code\\n</summary>\\n\\n<div>\\n\\n```yaml title=\\".github/workflows/testing.yaml\\" showLineNumbers\\n(...)\\n  unit-tests:\\n    strategy:\\n      matrix:\\n        os: [ubuntu-latest]\\n        node-version: [16, 18]\\n      // highlight-start\\n      include: # add the odd combination\\n        - os: windows-latest\\n          node-version: 18\\n      // highlight-end\\n    runs-on: ${{ matrix.os }}\\n        (...)\\n  ```\\n\\n</div>\\n</details>\\n\\n#### `exclude`\\n`exclude` works in the opposite direction: you add all values to the matrix and use `exclude` to **remove** the undesirable matches.\\n\\n<details>\\n<summary>\\n  Show code\\n</summary>\\n<div>\\n\\n```yaml title=\\".github/workflows/testing.yaml\\" showLineNumbers\\n(...)\\n  unit-tests:\\n    strategy:\\n      matrix:\\n        os: [ubuntu-latest, windows-latest]\\n        node-version: [16, 18]\\n      // highlight-start\\n      exclude: # remove unwanted combination\\n        - os: windows-latest\\n          node-version: 16\\n      // highlight-end\\n    runs-on: ${{ matrix.os }}\\n        (...)\\n  ```\\n\\n</div>\\n</details>\\n\\n<details>\\n<summary>\\n  Show pipeline: the pipeline looks the same in both cases\\n</summary>\\n<div>\\n\\nNow there are only 3 jobs - also, the job completion for windows went down from 1m23/1m35s to 44s thanks to caching :)\\n\\n![screenshot](./screenshot_15.png)\\n</div>\\n</details>\\n\\n\\n### The Declarative Case: `include` as a flattenning tool\\n\\nIf you prefer clarity over brevity, you can use `include` to flatten matrices. Just beware that this can make your workflow harder to maintain.\\n\\n<details>\\n<summary>\\n  Show code\\n</summary>\\n\\n<div>\\n\\n![screenshot](./screenshot_1.png)\\n</div>\\n</details>\\n\\n### Dynamic exclusions\\n\\nThis is my favourite. You can use `exclude` to dynamically adjust matrix values. \\n\\nLet\'s suppose your team decides that every Tuesday you will run tests in the most recent Node.js version, as a peek into changes you\'ll have to make in the future. You can use `include` to run the new version to the matrix *only on Tuesdays*.\\n\\n<details>\\n<summary>\\n  Show code\\n</summary>\\n\\n<div>\\n\\n```yaml title=\\".github/workflows/testing.yaml\\" showLineNumbers\\n  jobs:\\n    get_weekday:\\n      runs-on: ubuntu-latest\\n      outputs:\\n        WEEKDAY: ${{ steps.get_weekday.outputs.WEEKDAY }}\\n      steps:\\n        - name: Get day of the week\\n          id: get_weekday\\n          run: echo \\"WEEKDAY=$(date \'+%a\')\\" | tee -a \\"$GITHUB_OUTPUT\\"\\n\\n    unit-tests:\\n      runs-on: ubuntu-latest\\n      needs: get_weekday\\n      strategy:\\n        matrix:\\n          node-version: [16, 18, 24]\\n          // highlight-start\\n          exclude:\\n            - node-version: ${{ needs.get_weekday.outputs.WEEKDAY != \'Tue\' && 24 || \'\' }}\\n          // highlight-end\\n      steps:\\n        - name: Run unit tests\\n          run: |\\n            echo \\"Today is ${{ needs.get_weekday.outputs.WEEKDAY }}.\\"\\n            echo \\"Let\'s run tests for Node.js v${{ matrix.node-version }}\\"\\n      (...)\\n  ```\\n</div>\\n</details>\\n\\n<details>\\n<summary>\\n  Show pipeline\\n</summary>\\n<div>\\n\\n![screenshot](./screenshot_2.png)\\n</div>\\n</details>\\n\\nYou may have noticed this funny syntax: `${{ needs.get_weekday.outputs.WEEKDAY != \'Tue\' && 24 || \'\' }}`. This is a way to [use ternaries in Github Actions](https://docs.github.com/en/actions/learn-github-actions/expressions#:~:text=ternary,expressions). If the weekday *is not* Tuesday, this expression will return `24`, meaning that `24` will be excluded from the `node-version` array values. But, on Tuesdays, this expression will return an empty value => `24` will not be excluded =>  all node-versions set in the base matrix run => Node.js 24 will run.\\n\\nNow, why `exclude` instead of `include`?  \\nHonestly, I haven\'t found a decent way to get `included` to work with this use case. With `include`, the syntax would be dreadful:  We have to use a ternary both for key and value. You sure you want... this thing below? I sure don\'t.\\n\\n```yaml\\ninclude:\\n  - { \\"${{needs.get_weekday.outputs.WEEKDAY != \'Tue\' && \'node-version\' || \'\'}}\\": \\"${{needs.get_weekday.outputs.WEEKDAY != \'Tue\' && 24 || \'\'}}\\" }\\n```\\n\\n## Adjusting matrices with `include` & `exclude`, part II: the small print\\n\\n### What `include` doesn\'t do\\n\\nFirst, let\'s see what you **cannot/should not** do with `include`:\\n\\n#### `include` doesn\'t inherit the matrix key/value pairs\\n\\nJust because a key/value pair is present in the matrix, it doesn\'t mean `include` inherits it.  \\n\\n```yaml\\n    strategy:\\n        matrix:\\n          os: [windows-latest, ubuntu-latest]\\n          node-version: [18]\\n          region: [Asia, Latam]\\n          // highlight-start\\n          include:\\n            - os: macos-latest\\n          // highlight-end\\n    steps:\\n      - name: ${{ matrix.os }} ${{ matrix.node-version }} ${{ matrix.region }}\\n        run: |\\n          echo \\"OS: ${{ matrix.os }}\\"\\n          echo \\"Node Version: ${{ matrix.node-version }}\\"\\n          echo \\"Region: ${{ matrix.region }}\\"\\n```\\nIn this example, because you haven\'t defined a `node-version` or `region` in your include map, those values will be empty in the included job.\\n\\n\\n<details>\\n<summary>\\n  Show pipeline\\n</summary>\\n<div>\\n\\n![screenshot](./screenshot_16.png)\\n</div>\\n</details>\\n\\n#### Array values for `include` do not spread into separate jobs\\n\\nIn this example, the `region` array  **will not** spin a `macos-latest` job for each region. The `include` will spin a **single** MacOS job that takes the whole array as the value for `region`, as you can see in the screenshot below. You can, however, extract the values from the array using the bracket notation `matrix.region[0]`.\\n\\n```yaml\\n    strategy:\\n        matrix:\\n          os: [windows-latest, ubuntu-latest]\\n          node-version: [18]\\n          region: [Asia, Latam]\\n          include:\\n            - os: macos-latest\\n            // highlight-next-line\\n              region: [Asia, Latam]\\n    steps:\\n      - name: ${{ matrix.os }} ${{ matrix.region }}\\n        run: |\\n          echo \\"OS: ${{ matrix.os }}\\"\\n          echo \\"Node Version: ${{ matrix.node-version }}\\"\\n          echo \\"First Region: ${{ matrix.region[0] }}\\"\\n          echo \\"Second Region: ${{ matrix.region[1] }}\\"\\n```\\n<details>\\n<summary>\\n  Show pipeline\\n</summary>\\n<div>\\n\\n![screenshot](./screenshot_17.png)\\n</div>\\n</details>\\n\\n### Advice for using`include`\\n\\nNow, what you **can/must** do with `include`, some of which you might have guessed already from the previous points.  \\n\\n#### Be explicit about all desired key/value pairs to the matrix\\n\\nIf you want a key/value pair in `include`, well... include it. It won\'t magically appear by inheritance.\\n\\n```yaml\\n    strategy:\\n        matrix:\\n          os: [windows-latest, ubuntu-latest]\\n          node-version: [18]\\n          region: [Asia, Latam]\\n          // highlight-start\\n          include:\\n            - os: macos-latest\\n              node-version: 20\\n              region: Asia\\n          // highlight-end\\n    steps:\\n      - name: ${{ matrix.os }} ${{ matrix.node-version }} ${{ matrix.region }}\\n        run: |\\n          echo \\"OS: ${{ matrix.os }}\\"\\n          echo \\"Node Version: ${{ matrix.node-version }}\\"\\n          echo \\"Region: ${{ matrix.region }}\\"\\n```\\n\\n#### Each `include` map is an independent unit\\n\\nIn the previous example, the `macos-latest` job was only added to the `Asia` region. \\nIf you want  `macos-latest` for `Asia` and `Latam`, you need to add an `include` map for each of them. Do not try to combine them in a single map, that\'s not how `include` works.\\n\\n```yaml\\n    strategy:\\n        matrix:\\n          os: [windows-latest, ubuntu-latest]\\n          node-version: [18]\\n          region: [Asia, Latam]\\n          // highlight-start\\n          include:\\n            - os: macos-latest\\n              node-version: 20\\n              region: Asia\\n            - os: macos-latest\\n              node-version: 20\\n              region: Latam\\n          // highlight-end\\n    steps:\\n      - name: ${{ matrix.os }} ${{ matrix.node-version }} ${{ matrix.region }}\\n        run: |\\n          echo \\"OS: ${{ matrix.os }}\\"\\n          echo \\"Node Version: ${{ matrix.node-version }}\\"\\n          echo \\"Region: ${{ matrix.region }}\\"\\n```\\n\\n#### Feel free to add brand new keys not present in the base matrix\\n\\nYou\'re not restricted to modifying keys that already exist in the base matrix. You can add new ones too. Just keep in mind that \\"new\\" keys will be added to **all* jobs in the matrix.  \\n\\n```yaml\\n    strategy:\\n        matrix:\\n          os: [windows-latest, ubuntu-latest]\\n          node-version: [18]\\n          region: [Asia, Latam]\\n          // highlight-start\\n          include:\\n            - report: true\\n          // highlight-end\\n    steps:\\n      - name: ${{ matrix.os }} ${{ matrix.node-version }} ${{ matrix.region }} ${{ matrix.report }}\\n        run: |\\n          echo \\"OS: ${{ matrix.os }}\\"\\n          echo \\"Node Version: ${{ matrix.node-version }}\\"\\n          echo \\"Region: ${{ matrix.region }}\\"\\n          echo \\"Should report: ${{ matrix.report }}\\"\\n```\\n\\n<details>\\n<summary>\\n  Show pipeline\\n</summary>\\n<div>\\nRepating, just to highlight it:  \\n- When the keys of an `include` map don\'t match any keys in the base matrix (as in the example above), **that new key will be added to every job in the matrix**.  \\n\\n![screenshot](./screenshot_18.png)\\n</div>\\n</details>\\n\\n\\n## Case Study: More Complex Matrices\\n\\nWhen real life complexity knocks at your door, `include` and `exclude` can become confusing. I\'ll walk you through an implementation example to help you reason through your options.\\n\\nLet\'s take the following scenario: you need to run tests for your product, but different regions have different requirements for the test suite. But they have one thing in common: both regions require that you produce a report for all tests. Here are your specs:\\n\\nAsia Region:\\n- run tests for Node.js 18 in Ubuntu and Windows\\n- run tests for Node.js 20 in Ubuntu and MacOs \\n\\nLatam Region:\\n- run tests for Node.js 18 in Ubuntu and Windows\\n- run tests for Node.js 20 in Ubuntu only\\n- run tests for Node.js 22 in Windows, Ubuntu and MacOs\\n\\nExport test report:\\n- Adds a variable to the matrix to indicate if the test report should be exported. Your requirement is that all tests should output a report.\\n\\nFor clarity, I\'ll spell out what jobs will run for each product:\\n\\n| Config | Windows | Ubuntu | MacOs |\\n| --- | --- | --- | --- |\\n| Region: Asia | 18 | 18, 20 | 20 |\\n| Region: Latam | 18, 22 | 18, 20, 22 | 22 |\\n\\n\\n### The declarative approach\\n\\nWith this approach, you make each combination very explicit. It\'s quite easy to see how this can get a bit out of hand as your test suite grows.\\n\\nBut there\'s a silly trick to make it less awful to read: just tweak the `include` syntax using curly brackets. This is my favourite notation for matrices, as the visual pattern makes the reading more manageable.\\n\\n<details>\\n<summary>\\n  Show code\\n</summary>\\n\\n<div>\\n\\n```yaml title=\\".github/workflows/testing.yaml\\" showLineNumbers\\n(...)\\n  unit-tests:\\n    strategy:\\n      matrix:\\n      include:\\n        - {os: windows-latest, node-version: 18, region: Asia, report: true}\\n        - {os: windows-latest, node-version: 18, region: Latam, report: true}\\n        - {os: windows-latest, node-version: 22, region: Latam, report: true}\\n        - {os: ubuntu-latest, node-version: 18, region: Asia, report: true}\\n        - {os: ubuntu-latest, node-version: 18, region: Latam, report: true}\\n        - {os: ubuntu-latest, node-version: 20, region: Asia, report: true}\\n        - {os: ubuntu-latest, node-version: 20, region: Latam, report: true}\\n        - {os: ubuntu-latest, node-version: 22, region: Latam, report: true}\\n        - {os: macos-latest, node-version: 20, region: Asia, report: true}\\n        - {os: macos-latest, node-version: 22, region: Latam, report: true}\\n    runs-on: ${{ matrix.os }}\\n    steps:\\n      - name: Run tests\\n        run: | \\n          echo \\"Running tests for Node.js ${{ matrix.node-version }} in ${{ matrix.os }} for product ${{ matrix.product }}\\"\\n          echo \\"Should report: ${{ matrix.report }}\\"\\n      (...)\\n  ```\\n</div>\\n</details>\\n \\n### The `include`/`exclude` approach\\n\\nSome people might prefer this approach, but it requires a little training to tell what specific jobs will be actually spinned up.\\n\\nIn this example, we will build our base matrix with all applicable values: \\n\\n```yaml title=\\".github/workflows/testing.yaml\\"\\n  matrix:\\n    os: [windows-latest, ubuntu-latest, macos-latest]\\n    node-version: [18, 20, 22]\\n    region: [Asia, Latam]\\n```\\n\\n_As an exercise, how many jobs do we have there?_\\n```\\nos_length (3) * node-version_length (3) * region_length (2) = 18\\n```\\n\\nThen we can proceed to trim it down to the desired cases only.  \\nKeep in mind that `include` is processed after `exclude`, so we can use `include` to add back combinations that were previously excluded.\\n\\n```yaml \\n  matrix:\\n    os: [windows-latest, ubuntu-latest, macos-latest]\\n    node-version: [18, 20, 22]\\n    region: [Asia, Latam]\\n    exclude:\\n      - {node-version: 22, region: Asia}                        # Asia has no case for Node.js 22 (-3 jobs)\\n      - {node-version: 18, os: macos-latest}                    # MacOs won\'t test Node.js 18 (-2 jobs)\\n      - {node-version: 20, region: Asia, os: windows-latest}    # Windows is the only case without Node.js 20 in Asia (-1 job)\\n      - {node-version: 20, region: Latam}                       # There\'s only one case for Node 20 in Latam, we\'ll readd it later (-3 jobs)\\n    include:\\n      - {node-version: 20, region: Latam, os: ubuntu-latest}    # Re-adding the case for Node 20 in Latam (+1 job)\\n```\\n\\n<details>\\n<summary>\\n  Show pipeline\\n</summary>\\n<div>\\n\\n![screenshot](./screenshot_19.png)\\n</div>\\n</details>\\n\\n\\nAnd finally, because the report should be added to all cases, we can add `report` under `include`:\\n\\n```yaml \\n  matrix:\\n    os: [windows-latest, ubuntu-latest, macos-latest]\\n    node-version: [18, 20, 22]\\n    region: [Asia, Latam]\\n    exclude:\\n      - {node-version: 22, region: Asia}\\n      - {node-version: 18, os: macos-latest}\\n      - {node-version: 20, region: Asia, os: windows-latest}\\n      - {node-version: 20, region: Latam}\\n    include:\\n      - {node-version: 20, region: Latam, os: ubuntu-latest}\\n      // highlight-start\\n      # doesn\'t add new jobs, just adds this key to all jobs\\n      - report: true \\n      // highlight-end\\n```\\n\\n<details>\\n<summary>\\n  Show pipeline\\n</summary>\\n<div>\\n\\n![screenshot](./screenshot_20.png)\\n</div>\\n</details>\\n\\nAnd that\'s how we end with our 10 desired jobs.\\n\\n## Simplifying \\"particular combinations\\" in matrices\\n\\nIf you\'re using multidimensional matrices, the more configurations you set, the more difficult it is to handle outliers. So here\'s a trick I learned from [Sean Killeen\'s blog](https://seankilleen.com/2023/08/how-to-specify-pairs-of-items-in-github-actions-matrix-strategies/): instead of using `include`, `exclude` and whatnot, you can use maps to easily group key/value pairs that usually go together but don\'t quite fit a matrix context because they are too tighly coupled. It won\'t work for all cases, but will be a good solution for plenty of them:\\n\\n\\n```yaml title=\\".github/workflows/sean.yaml\\" showLineNumbers\\njobs:\\n  build_release:\\n    name: \\"Build and Release\\"\\n    strategy:\\n      matrix:\\n        // highlight-next-line\\n        VERSIONS: [ {ruby: 2.7.3, ghpages: 226}, {ruby: 2.7.4, ghpages: 228}] # tight coupling between rub and ghpages versions, not very \\"matrixy\\"\\n        NODE_MAJOR_VERSION: [16,18,20]\\n    runs-on: ubuntu-latest\\n    env:\\n      NODE_MAJOR_VERSION: ${{ matrix.NODE_MAJOR_VERSION }}\\n      // highlight-start\\n      RUBY_VERSION: ${{ matrix.VERSIONS.ruby }}\\n      GITHUB_PAGES_VERSION: ${{ matrix.VERSIONS.ghpages }}\\n      // highlight-end\\n```\\n\\n\x3c!-- \\n## TODO: Generating Your Own Matrix\\n\\nA matrix, in itself, is nothing more than a JSON. \\n\\n```json title=\\"matrix.json\\" { \\"props\\": { \\"style\\": { \\"maxHeight\\": \\"300px\\" } } }\\n{\\n  \\"include\\": [\\n    {\\n      \\"project\\": \\"foo\\",\\n      \\"config\\": \\"Debug\\"\\n    },\\n    {\\n      \\"project\\": \\"bar\\",\\n      \\"config\\": \\"Release\\"\\n    }\\n  ]\\n}\\n```\\n\\njobs:\\n  prepare:\\n    runs-on: ubuntu-latest\\n    outputs:\\n      repository: ${{ steps.json.outputs.repository }}\\n    steps:\\n      - name: build matrix\\n        id: json\\n        run: |\\n          repository=\'{ \\"repository\\": [\\"repo1\\",\\"repo2\\",\\"repo3\\",\\"repo4\\"] }\'\\n          echo \\"repository=$repository\\" >> \\"$GITHUB_OUTPUT\\"\\n\\n  run-matrix:\\n    needs: prepare\\n    runs-on: ubuntu-latest\\n    strategy:\\n      fail-fast: false\\n      matrix: ${{ fromJson(needs.prepare.outputs.repository) }}\\n    steps:\\n      - run: echo \\"${{ matrix.repository }}\\" --\x3e --\x3e\\n\\n\x3c!-- \\n## TODO: Resource Management: Max Number of Concurrent Jobs\\n\\nhttps://docs.github.com/en/actions/using-jobs/using-a-matrix-for-your-jobs#defining-the-maximum-number-of-concurrent-jobs --\x3e\\n\\n## Handling glitches in the matrix\\n\\n### Matrix job failures\\nIt\'s true that jobs run in parallel and are independent of each other. But when they are spin up by a matrix, by default, all are cancelled if one of them fails. This is not always desirable, so you can change that behaviour.\\n\\n| Option | Scope | Effects |\\n| --- | --- | --- |\\n| `fail-fast: <boolean>` | Entire matrix | Default: `true`. Determines if **all** ongoing and queued matrix jobs will be cancelled if one job fails |\\n| `continue-on-error: <boolean>` | Job level | Determines if a failure on a job will bypass `fail-fast: true` |\\n| `matrix.experimental: <boolean>` | Job level | Allows jobs to have different `continue-on-error` values |\\n\\n```yaml title=\\".github/workflows/testing.yaml\\" showLineNumbers\\njobs:\\n  unit-tests:\\n    continue-on-error: false  # default value, can be ommited\\n    strategy:\\n      // highlight-start\\n      fail-fast: true           # default value, can be ommited\\n      // highlight-end\\n      matrix:\\n        node-version: [14, 16, 18]\\n      runs-on: ubuntu-latest\\n    steps:\\n      (...)\\n```\\n\\n#### `fail-fast`\\n\\n`fail-fast` is  pretty straightforward. `true` will short-circuit the matrix if one job fails; `false` makes all jobs run independently of each other regardless of job failures.\\n\\n#### `continue-on-error`\\n\\n`continue-on-error` is a way to add an exclusion to the `fail-fast` setting.\\n\\nA matrix with `fail-fast: true` will not fail if `continue-on-error` is `true`. The opposite also stands: a matrix with `fail-fast: false` will fail if `continue-on-error: false` is set.  \\n\\nReminder: `continue-on-error` can be used at the step level to prevent a job from failing should that step fail. It can also be used independently of matrices.\\n\\nIf used alone, `continue-on-error` might at best cancel out `fail-fast`, which is not a big advantage. The real leverage comes when `matrix.experimental is added to the mix.  \\n\\n#### `matrix.experimental`\\n\\n`matrix-experimental` allows matrix jobs to have different `continue-on-error` values. This way, you can granularly define which failing jobs should or shouldn\'t halt ongoing & queued jobs. \\n\\nAn example: you are evaluating a new unstable Node.js version and you want to observe it for a while before release. You don\'t want the whole matrix to fail if your little experiment fails the tests; it should only fail if stable versions raise issues.  \\nTo exclude that one job, you can `include` the new version to the matrix and setting that job as the only one with an experimental value of `true`:\\n\\n<details>\\n<summary>\\n  Show code\\n</summary>\\n<div>\\n\\n```yaml title=\\".github/workflows/testing.yaml\\" showLineNumbers\\njobs:\\n  unit-tests:\\n    strategy:\\n      runs-on: ubuntu-latest\\n      // highlight-start\\n      # ommited fail-fast as it\'s true by default\\n      continue-on-error: ${{ matrix.experimental }} # dynamically set for each job\\n      matrix:\\n        node-version: [18, 20]\\n        experimental: [false] # will populate continue-on-error with false\\n        include:\\n          - node-version: 21\\n            experimental: true # will populate continue-on-error with true, but only for the job running Node v21.\\n      // highlight-end\\n    steps:\\n      (...)\\n```\\n\\nSo the resulting jobs from this matrix will be:\\n\\n- node 18, continue-on-error: false\\n- node 20, continue-on-error: false\\n- node 21, continue-on-error: true\\n\\n</div>\\n</details>\\n\\n### Dynamically-generated matrices: Handling Empty Matrix Error\\n\\n_(This section will make more sense once I add the section about dynamically-generated matrices)_  \\nIf you are using dynamically generated matrices, your workflow may fail if the matrix ends up spinning an empty result:\\n\\n```\\nError when evaluating \'strategy\' for job \'xxxxx\'. .github/workflows/my_worflow.yaml (Line: X, Col: Y): Matrix must define at least one vector\\n\\n```\\n\\nThe fix is to execute the dependent job with a conditional:\\n\\n```yaml\\napply:\\n  name: \'${{ matrix.account }}\'\\n  needs: generate\\n  // highlight-next-line\\n  if: ${{ fromJson(needs.generate.outputs.matrix).include[0] }}\\n  strategy:\\n    fail-fast: false\\n    matrix:\\n      include: ${{ fromJSON(needs.generate.outputs.matrix) }}\\n```\\nWhat is happening here?  \\n\\nThe conditional converts the JSON string to an object, and checks if the `include` key has at least one map. Use fearlessly, because matrices contain the `includes` property whenever a  matrix has any elements - it doesn\'t depend on using he `include` keyword explicitly on the matrix definition.  \\n\\n\\n\x3c!-- ## TODO: Advanced use of matrices with reusable workflows\\n\\nI owe this one to [Alexander Kondratskiy in Slack Overflow](https://stackoverflow.com/users/436025/alexander-kondratskiy), and it\'s a very cool use case.\\n\\nImagine you have job_B, dependendt on job_A, and both use matrices. job_B will only start running once **all jobs** in matrix A have completed.  \\n\\nBut what if you\'d like job_B_node_18 to be triggered as soon as job_A_node_18 is completed, instead of waiting for who knows how many jobs complete?\\n\\nHis solution was to create a reusable workflow that traversed the matrix and made \\"the entire workflow of jobs run unimpeded, in parallel\\". [Go check that thing of beauty at SO](https://stackoverflow.com/questions/75318609/matrix-strategy-over-entire-workflow-in-github-actions).\\n\\nI\'ll write a post about reusable workflows soon, this post is already ridiculously long \ud83d\ude05 --\x3e\\n\\n\x3c!-- <https://stackoverflow.com/questions/75318609/matrix-strategy-over-entire-workflow-in-github-actions> --\x3e\\n\\n\x3c!-- How to share matrix between jobs https://github.com/orgs/community/discussions/26284\\n\\nHow use strategy/matrix with script https://stackoverflow.com/questions/59977364/github-actions-how-use-strategy-matrix-with-script\\n\\nhttps://michaelheap.com/dynamic-matrix-generation-github-actions/ --\x3e\\n\\n\\n##\xa0WIP Sections\\n\\nCome back later! I\'ve started drafting content for the following sections:\\n\\n- Limitations (e.g. Matrix outputs don\'t work neatly, they require artifacts)\\n- Dynamically-generated Matrices\\n- Resource Management: Max Number of Concurrent Jobs\\n- Advanced use of matrices with reusable workflows\\n- Sharing a matrix between jobs"},{"id":"github-actions-data-flow","metadata":{"permalink":"/blog/pt-BR/tech/github-actions-data-flow","source":"@site/i18n/pt-BR/docusaurus-plugin-content-blog-tech/2023-10-31-github-actions-data-flow/index.md","title":"GitHub Actions: Fluxo e Persist\xeancia de Dados em Workflows","description":"Quando se trata de Github Actions, os dados n\xe3o s\xe3o persistentes por natureza, nem ficam dispon\xedveis para todo o pipeline. Cada etapa (step) tem seu pr\xf3prio processo, cada trabalho (job) tem seu pr\xf3prio executor (runner). Por padr\xe3o, quaisquer dados que surjam em um trabalho terminam com ele.","date":"2023-10-31T00:00:00.000Z","tags":[{"label":"github actions","permalink":"/blog/pt-BR/tech/tags/github-actions"},{"label":"ci/cd","permalink":"/blog/pt-BR/tech/tags/ci-cd"},{"label":"pipeline","permalink":"/blog/pt-BR/tech/tags/pipeline"},{"label":"env","permalink":"/blog/pt-BR/tech/tags/env"},{"label":"outputs","permalink":"/blog/pt-BR/tech/tags/outputs"},{"label":"artefatos","permalink":"/blog/pt-BR/tech/tags/artefatos"},{"label":"cache","permalink":"/blog/pt-BR/tech/tags/cache"}],"readingTime":11.565,"hasTruncateMarker":true,"authors":[{"name":"Manu Magalh\xe3es","title":"Engenheira de DevSecOps","url":"https://github.com/magmanu","imageURL":"https://github.com/magmanu.png","key":"manu"}],"frontMatter":{"slug":"github-actions-data-flow","title":"GitHub Actions: Fluxo e Persist\xeancia de Dados em Workflows","authors":"manu","tags":["github actions","ci/cd","pipeline","env","outputs","artefatos","cache"]},"unlisted":false,"prevItem":{"title":"An Ultimate Guide to Matrices in GitHub Actions, from Basic to Advanced","permalink":"/blog/pt-BR/tech/matrices-github-actions"},"nextItem":{"title":"Como Gerar JSON Din\xe2mico no Terraform","permalink":"/blog/pt-BR/tech/dynamic-json-in-terraform"}},"content":"Quando se trata de Github Actions, os dados n\xe3o s\xe3o persistentes por natureza, nem ficam dispon\xedveis para todo o pipeline. Cada etapa (step) tem seu pr\xf3prio processo, cada trabalho (job) tem seu pr\xf3prio executor (runner). Por padr\xe3o, quaisquer dados que surjam em um trabalho terminam com ele.\\n\\nEnt\xe3o, como podemos passar dados de um processo para outro, ou salvar dados para uma execu\xe7\xe3o futura?\\n\\nA resposta r\xe1pida e certeira \xe9 essa:\\n\\n| Estrat\xe9gia | Dados | Escopo | Persist\xeancia | Detalhes | Exemplo |\\n| --- | --- | --- | --- | --- | --- |\\n| `env` | Valores | Trabalho (interno) | Ef\xeamero | Propaga _dados_ <br/> entre _etapas_ <br/> no mesmo _trabalho_ | Passar um booleano para determinar se a pr\xf3xima estapa deve ser executada |\\n| `outputs` | Valores | Fluxo de trabalho (interno) | Ef\xeamero | Propaga _dados_ <br/> entre _trabalhos/etapas_ <br/> no mesmo _fluxo de trabalho_ | Passar um ID  para o pr\xf3ximo trabalho |\\n| artefatos | Arquivos | Fluxo de trabalho (interno e externo) | Persistente | Propaga _arquivos_ <br/> entre _trabalhos/fluxos de trabalho_ | Passar o build de um projeto para diferentes trabalhos de teste executados em paralelo <br/><br/> _Prefer\xeancia a dados que mudam frequentemente. Os arquivos ficam dispon\xedveis para download ap\xf3s o t\xe9rmino do fluxo de trabalho._ |\\n| cache | Arquivos | Fluxo de trabalho (interno e externo) | Persistente | Propaga _arquivos_ <br/> dentro e entre _fluxos de trabalho_ <br/> no mesmo _reposit\xf3rio_ | Armazenar pacotes npm em cache para uso em diferentes execu\xe7\xf5es de fluxo de trabalho. <br/><br/> _Destinado a arquivos que n\xe3o mudam muito._ |\\n\\nPara uma resposta mais completa, continue lendo.\\nTodos os exemplos de fluxo de trabalho neste artigo \u200b\u200b[est\xe3o disponiveis em formato de arquivo aqui](https://github.com/magmanu/blog/tree/main/demos/github-actions-data-flow), junto com uma c\xf3pia dos respectivos logs editados (em ingl\xeas).\\n\\n\x3c!--truncate--\x3e\\n\\n## Como usar `env`\\n\\n\xc9 muito simples transferir dados entre etapas: defina um par chave-valor (key/value) e grave-o no arquivo de ambiente `GITHUB_ENV`, usando a sintaxe apropriada para seu shell. Veja exemplos abaixo em bash e python:\\n\\n<details>\\n   <summary>\\n     Exibir c\xf3digo\\n   </summary>\\n   <div>\\n\\n```yaml title=\\"/.github/workflows/using_env.yaml\\"\\n    steps:\\n      - name: Duas formas de definir vari\xe1veis de ambiente\\n      # Aviso: nesta etapa, o input n\xe3o foi sanitizado nem validado\\n        shell: bash\\n        run: |\\n          # N\xe3o exibe a vari\xe1vel nos logs.\\n          wikipedia_aleatorio_1=$(curl -L -X GET \\"https://en.wikipedia.org/api/rest_v1/page/random/summary\\" | jq .title)\\n          echo \\"$wikipedia_aleatorio_1\\"\\n          echo \\"ARTIGO_1=$wikipedia_aleatorio_1\\" >> \\"$GITHUB_ENV\\"\\n          # \ud83d\udc09 Exibe a vari\xe1vel nos logs: use apenas com dados que n\xe3o sejam confidenciais!\\n          wikipedia_aleatorio_2=$(curl -L -X GET \\"https://en.wikipedia.org/api/rest_v1/page/random/summary\\" | jq .title)\\n          echo \\"ARTIGO_2=$wikipedia_aleatorio_2\\" | tee -a \\"$GITHUB_ENV\\"\\n\\n      - name: Definir vari\xe1veis de ambiente em python\\n        shell: python\\n        # se usar \\"write\\", use \\\\n ao criar mais de uma vari\xe1vel\\n        # com \\"print\\", \\\\n n\xe3o \xe9 necess\xe1rio\\n        run: |\\n          from os import environ as env\\n          with open(env.get(\'GITHUB_ENV\', None), \'a\') as ghenv:\\n            ghenv.write(\\"SUJEITO=Sun\\\\n\\")\\n            print(\\"ESTADO=radiant\\", file=ghenv)\\n            print(\\"DIA=today\\", file=ghenv)\\n          \\n      - name: \ud83d\udee1\ufe0f Recuperando valores de forma segura\\n        # observe que ARTIGO_1 n\xe3o foi sanitizado ou validado, por isso, est\xe1 vulner\xe1vel a ataques de inje\xe7\xe3o.\\n        # A abordagem abaixo evita o problema ao passar ARTIGO_1 como argumento para o script.\\n        # Tamb\xe9m \xe9 poss\xedvel renamear as vari\xe1veis\\n        env:\\n          QUEM: ${{ env.SUJEITO }}\\n          QUE: ${{ env.ARTIGO_1 }}\\n          QUANDO: ${{ env.DIA }}\\n        run: |\\n          echo \\"$QUEM leu sobre $QUE $QUANDO.\\"\\n        \\n      - name: \ud83d\udc09 Recuperando valores de forma potencialmente vulner\xe1vel\\n        # Esta abordagem \xe9 vulner\xe1vel a ataques de inje\xe7\xe3o!\\n        # Use apenas se voc\xea tiver controle sobre o input\\n        shell: bash\\n        run: |\\n          echo \\"${{ env.SUJEITO }} est\xe1 ${{ env.ESTADO }} ${{ env.DIA }}.\\"\\n```\\n\\n   </div>\\n</details>\\n\\n#### Dica de debug\\nPara listar todas as vari\xe1veis \u200b\u200bde ambiente dispon\xedveis em um trabalho, adicione esta pequena etapa:\\n\\n```- run: env```\\n\\n## Como usar `outputs`\\n\\nOs outputs ficam dispon\xedveis para todas as etapas do mesmo trabalho e para qualquer trabalho subsequente que precise deles.\\nOutputs sempre s\xe3o **strings** unicode.\\n\\nE obviamente, trabalhos que dependem de um `output` n\xe3o ser\xe3o executados em paralelo com o trabalho que produz o output.\\n\\n<details>\\n   <summary>\\n     Mostrar c\xf3digo\\n   </summary>\\n   <div>\\n\\nPara simplificar, o output foi definido em bash, mas voc\xea pode usar o shell que preferir.\\n\\n```yaml title=\\"/.github/workflows/outputs-for-different-job.yaml\\"\\njobs:\\n  definicao-de-output:\\n    runs-on: ubuntu-latest\\n    // highlight-start\\n    outputs:  # Obrigat\xf3rio: defina o output no trabalho para que fique dispon\xedvel a outros trabalhos\\n      nome: ${{ steps.valor-estatico.outputs.NOME }}\\n      lugar: ${{ steps.valor-dinamico.outputs.LUGAR }}\\n    // highlight-end\\n    steps:\\n      - id: valor-estatico\\n        run: |\\n          // highlight-next-line\\n          echo \\"NOME=Marcela\\" >> \\"$GITHUB_OUTPUT\\"\\n      \\n      - id: valor-dinamico\\n        # Observe o use de jq -c para obter o valor como uma \xfanica linha\\n        run: |\\n          lugar=$(curl -H \\"Accept: application/json\\" https://randomuser.me/api/ | jq -c .results[].lugar)\\n          // highlight-next-line\\n          echo \\"LUGAR=$lugar\\" > \\"$GITHUB_OUTPUT\\"\\n\\n  recuperacao-de--outputs:\\n    runs-on: ubuntu-latest\\n    needs: definicao-de-output\\n    steps:\\n      - name: boas-vindas\\n        run: |\\n          PAIS=$(echo $GEODATA | jq -r . | jq .PAIS)\\n          echo \\"Ol\xe1 $nome! $PAIS \xe9/s\xe3o um lindo pa\xeds, divirta-se!\\"\\n         // highlight-start\\n        env:\\n          name: ${{needs.definicao-de-output.outputs.nome}}\\n          GEODATA: ${{ needs.definicao-de-output.outputs.lugar }}\\n        // highlight-end\\n```\\n   </div>\\n</details>\\n\\nEmbora seja recomendado usar `env` para passar dados entre etapas, `outputs` tamb\xe9m pode ser usado. Isso \xe9 \xfatil quando um valor \xe9 necess\xe1rio tanto no trabalho atual quanto nos trabalhos a seguir.\\n\\n<details>\\n   <summary>\\n     Mostrar c\xf3digo\\n   </summary>\\n   <div>\\n\\nO exemplo anterior mostrou como usar outputs em diferentes trabalhos.\\nPara usar um output no trabalho em que ele \xe9 definido, basta adicionar o c\xf3digo em destaque abaixo.\\n\\n```yaml title=\\"/.github/workflows/outputs-for-same-job.yaml\\"\\njobs:\\n  definicao-de-output:\\n    runs-on: ubuntu-latest\\n    outputs:\\n      name: ${{ steps.valor-estatico.outputs.NOME }}\\n      lugar: ${{ steps.valor-dinamico.outputs.LUGAR }}\\n    steps:\\n      - id: valor-estatico\\n        run: |\\n          echo \\"NOME=Marcela\\" >> \\"$GITHUB_OUTPUT\\"\\n      // highlight-start\\n      - name: Consumir o output no mesmo trabalho\\n        run: |\\n          echo \\"$NOME, $GEODATA \xe9 sua localiza\xe7\xe3o. Atualizamos seu fuso hor\xe1rio para GMT$OFFSET.\\"\\n        env:\\n          NOME: ${{ steps.valor-estatico.outputs.NOME }}\\n          # Use fromJSON() direto no env ao filtrar o valor do output ainda no env\\n          # Veja mais sobre filtragem de objetos em  \\n          # https://docs.github.com/en/actions/learn-github-actions/expressions#object-filters\\n          GEODATA: ${{ fromJSON(steps.valor-dinamico.outputs.LUGAR).country }}\\n          OFFSET: ${{ fromJSON(steps.valor-dinamico.outputs.LUGAR).timezone.offset }}\\n      // highlight-end\\n\\n    (...)\\n```\\n   </div>\\n</details>\\n\\n:::info Dica de debug\\n\\n- Um output individual deve ter no m\xe1ximo 1 MB.\\n- Todos os outputs combinados n\xe3o devem exceder 50MB.\\n\\n:::\\n\\n<br/>\\n\\n:::tip XP da vida Real\\n\\n`GITHUB_OUTPUT` espera uma string de apenas uma linha.\\nSe precisar de um output com v\xe1rias linhas, atribua-as a uma vari\xe1vel e construa o output assim:\\n\\n```bash\\necho \\"NOME_DO_PAYLOAD<<EOF\\"$\'\\\\n\'\\"$valor_do_payload\\"$\'\\\\n\'EOF >> \\"$GITHUB_OUTPUT\\".\\n```\\n\\n:::\\n\\n## Como usar  artefatos\\n\\nA documenta\xe7\xe3o diz: _Use artefatos quando desejar salvar arquivos produzidos por um trabalho para visualiza\xe7\xe3o ap\xf3s o t\xe9rmino da execu\xe7\xe3o do fluxo de trabalho, como bin\xe1rios compilados ou logs de compila\xe7\xe3o_. (tradu\xe7\xe3o livre)\\n\\n\\n### Subir artefatos\\n\\nVoc\xea pode:\\n- selecionar um ou v\xe1rios arquivos para serem agrupados como um artefato.\\n- usar curingas (wildcards), v\xe1rios caminhos (paths) e padr\xf5es (patterns) de exclus\xe3o com a sintaxe de sempre do GitHub Actions.\\n- definir um per\xedodo de reten\xe7\xe3o para o artefato.\\n\\n```yaml title=\\"/.github/workflows/handle-artefacts.yaml\\"\\njobs:\\n  upload:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - name: Checkout\\n        uses: actions/checkout@v4\\n      - name: Fazer upload de logs\\n        uses: actions/upload-artifact@v4\\n        with:\\n          name: todos-os-logs       # nome do artefato\\n          path: |                   # caminho dos arquivos inclu\xeddos no artefato\\n            **/log*.txt             # caminhos relativos t\xeam como base o $GITHUB_WORKSPACE\\n          retention-days: 1\\n          if-no-files-found: error  # for\xe7ar etapa a falhar se o conte\xfado a ser inclu\xeddo no artefato n\xe3o for encontrado\\n```\\n\\nObserve que o per\xedodo m\xe1ximo de reten\xe7\xe3o [pode ser definido em n\xedvel de reposit\xf3rio, organiza\xe7\xe3o ou empresa](https://docs.github.com/en/actions/learn-github-actions/usage-limits-billing-and-administration#artifact-and-log-retention-policy). H\xe1 um m\xe1ximo de 90 dias para reposit\xf3rios p\xfablicos e de 400 dias para reposit\xf3rios privados. Se voc\xea diminuir o per\xedodo de reten\xe7\xe3o, ter\xe1 mais espa\xe7o de gra\xe7a ;)\\n\\n### Baixar artefatos\\n\\nPara recuperar o artefato, voc\xea pode usar:\\n- a [UI do GitHub](https://docs.github.com/en/actions/managing-workflow-runs/downloading-workflow-artifacts)\\n- a [API do GitHub](https://docs.github.com/en/rest/actions/artifacts?apiVersion=2022-11-28#download-an-artifact)\\n- o [`gh` cli](https://docs.github.com/en/actions/managing-workflow-runs/downloading-workflow-artifacts?tool=cli)\\n- a a\xe7\xe3o oficial [`actions/download-artifact`](https://github.com/marketplace/actions/download-a-build-artifact), se precisar recuperar artefatos de maneira program\xe1tica. A partir da `v4`, a a\xe7\xe3o permite baixar artefatos de diferentes fluxos de trabalho ou reposit\xf3rios, desde que voc\xea forne\xe7a um token. (\ud83d\udee1\ufe0f: \xe9 recomendado usar um aplicativo GitHub em vez de um PAT em projetos profissionais.)\\n\\nVamos ver como recuperar o artefato que criamos no exemplo anterior usando `actions/download-artifact`:\\n\\n```yaml title=\\"/.github/workflows/handle-artefacts.yaml\\"\\ndownload:\\n    runs-on: ubuntu-latest\\n    needs: upload\\n    steps:\\n      - name: Baixar artefatos\\n        id: baixar-artefatos\\n        uses: actions/download-artifact@v4\\n        with:\\n          name: todos-os-logs  # \xe9 o nome definido na etapa de upload\\n        \\n      - name: Usar o artefato em um c\xf3digo python\\n        shell: python\\n        run: |\\n          import os\\n          from glob import glob\\n          caminho_artefato = os.environ.get(\\"CAMINHO\\", \\"\\")\\n          glob_list = glob(caminho_artefato + \\"/*.txt\\")\\n          for nome_arquivo in glob_list:\\n              with open(nome_arquivo, \\"r\\", encoding=\\"UTF-8\\") as f:\\n                  conteudo = f.read()\\n                  print(conteudo)\\n        env:\\n          CAMINHO: ${{ steps.baixar-artefatos.outputs.download-path }}\\n```\\n\\nAs a\xe7\xf5es de upload e download gerenciam o zip e o unzip dos artefatos automaticamente.\\n\\n### Apagar artefatos\\n\\nPara excluir um artefato, voc\xea pode:\\n- usar a [UI do GitHub](https://docs.github.com/en/actions/managing-workflow-runs/removing-workflow-artifacts)\\n- usar a [API do GitHub](https://docs.github.com/en/rest/reference/actions#delete-an-artifact)\\n- escrever um [script personalizado usando a API do Github](https://gist.github.com/qwe321qwe321qwe321/efae4569576006624c34f23b2dd76a58) ou usar uma [a\xe7\xe3o criada pela comunidade](https://github.com/GeekyEggo/delete-artifact).\\n\\n## Como usar cache\\n\\n:::danger \ud83d\udc09 Aviso de seguran\xe7a\\n\\nN\xe3o armazene informa\xe7\xf5es confidenciais no cache (cuidado com arquivos de configura\xe7\xe3o contendo senhas!), pois o cache \xe9 acess\xedvel a qualquer pessoa com direito de criar um PR no reposit\xf3rio - isso inclui forks!\\n\\n:::\\n\\nEste post j\xe1 est\xe1 grande demais. Vou tentar ser mais objetiva ao explicar cache:\\n\\n- Se voc\xea estiver usando executores auto-hospedados (self-hosted runners), a op\xe7\xe3o de armazenar o cache na sua pr\xf3pria infra s\xf3 est\xe1 dispon\xedvel nos planos Enterprise.\\n- A a\xe7\xe3o de cache requer um `path` para o cache e uma `key`. A `key` \xe9 usada para recuperar o cache e recri\xe1-lo numa pr\xf3xima vez.\\n- Quando o trabalho termina, a a\xe7\xe3o injeta automaticamente uma etapa p\xf3s-cache que atualiza o cache caso novas depend\xeancias sejam instaladas.\\n- Esta a\xe7\xe3o gerencia o cache de forma central. Isso significa que o cache fica dispon\xedvel (e atualiz\xe1vel) a todos os trabalhos no mesmo reposit\xf3rio, e tamb\xe9m a outros fluxos de trabalho.\\n\\n- Leia mais sobre [estrat\xe9gias de cache aqui](https://github.com/actions/cache/blob/main/caching-strategies.md) (em ingl\xeas).\\n\\n```yaml title=\\"/.github/workflows/cache.yaml\\"\\njobs:\\n  cache:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - uses: actions/checkout@v4\\n      - uses: actions/setup-python@v5\\n        with:\\n          python-version: \'3.12\'\\n          cache: \'pip\'\\n          cache-dependency-path: |\\n            **/requirements.txt\\n      \\n      - name: Obter diret\xf3rio de cache do  pip\\n        id: pip-cache\\n        run: |\\n          echo \\"dir=$(pip cache dir)\\" >> $GITHUB_OUTPUT\\n\\n      - name: Controlar cache para depend\xeancias do python\\n        uses: actions/cache@v3\\n        id: cache\\n        with:\\n          path: ${{ steps.pip-cache.outputs.dir }}\\n          key: ${{ runner.os }}-pip-${{ hashFiles(\'**/requirements.txt\') }}\\n        \\n      - name: Instalar depend\xeancias quando cache n\xe3o for id\xeantico\\n        if: steps.cache.outputs.cache-hit != \'true\'\\n        run: pip install -r requirements.txt\\n```\\n\\nSe quiser ver a prova do crime, veja os logs salvos (em ingl\xeas):\\n- [logs da defini\xe7\xe3o do cache](https://raw.githubusercontent.com/magmanu/blog/main/demos/github-actions-data-flow/31_data_flow_cache_set-cache.txt): primeira execu\xe7\xe3o, n\xe3o h\xe1 cache, ent\xe3o o cache \xe9 definido\\n- [logs do uso do cache](https://raw.githubusercontent.com/magmanu/blog/main/demos/github-actions-data-flow/32_data_flow_cache_use-cache.txt): na segunda execu\xe7\xe3o, o cache \xe9 encontrado e usado\\n- [logs de atualiza\xe7\xe3o do cache](https://raw.githubusercontent.com/magmanu/blog/main/demos/github-actions-data-flow/33_data_flow_cache_update-cache.txt): o arquivo requirements.txt foi alterado, ent\xe3o o cache n\xe3o coincide. As depend\xeancias s\xe3o reinstaladas e o cache \xe9 atualizado.\\n\\nCuriosidade: voc\xea notou a fun\xe7\xe3o `hashFiles` usada na etapa acima?  \\n\xc9 uma fun\xe7\xe3o fornecida pelo GitHub Actions para criar um valor hash exclusivo ligado a um arquivo. Quando o valor do hash n\xe3o coincide, significa que as depend\xeancias foram alteradas, o que invalida o cache. Assim, as depend\xeancias s\xe3o instaladas e o cache \xe9 atualizado em uma tarefa p\xf3s-cache.\\n\\nAt\xe9 mais! :)\\n\\n\\n\\n## Using cache\\n\\n:::danger \ud83d\udc09 Security warning\\n\\nDo not store sensitive information in the cache (beware of configuration files containing secrets), as the cache is accessible to anyone who can create a PR on the repository, even on forks.\\n\\n:::\\n\\nQuando lidamos com dados est\xe1veis que s\xe3o\u200b\u200b usados \u200b\u200brepetidamente (por exemplo, depend\xeancias), podemos usar cache para melhorar o desempenho da pipeline.  \\n\\nNo exemplo abaixo, vamos armazenar em cache as depend\xeancias `pip`. Repare que a etapa de cache foi colocada antes da etapa de instala\xe7\xe3o das depend\xeancias: a ideia \xe9 que a instala\xe7\xe3o s\xf3 aconte\xe7a se o cache estiver desatualizado ou inexistente.  \\n\\n```yaml title=\\"/.github/workflows/cache.yaml\\"\\njobs:\\n  cache:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - uses: actions/checkout@v4\\n      - uses: actions/setup-python@v5\\n        with:\\n          python-version: \'3.12\'\\n          cache: \'pip\'\\n          cache-dependency-path: |\\n            **/requirements.txt\\n      \\n      - name: Obter diret\xf3rio de cache do  pip\\n        id: pip-cache\\n        run: |\\n          echo \\"dir=$(pip cache dir)\\" >> $GITHUB_OUTPUT\\n\\n      - name: Controlar cache para depend\xeancias do python\\n        uses: actions/cache@v3\\n        id: cache\\n        with:\\n          # path: localiza\xe7\xe3o dos arquivos a serem armazenados em cache\\n          path: ${{ steps.pip-cache.outputs.dir }}\\n          # key: id \xfanico usado para recuperar e recriar o cache\\n          key: ${{ runner.os }}-pip-${{ hashFiles(\'**/requirements.txt\') }}\\n        \\n      - name: Instalar depend\xeancias quando cache n\xe3o for id\xeantico\\n        if: steps.cache.outputs.cache-hit != \'true\'\\n        run: pip install -r requirements.txt\\n```\\n\\n### Configurando o cache\\n\\nNa primeira vez que o fluxo de trabalho \xe9 executado, obviamente o cache est\xe1 vazio. Por isso, o output `cache-hit` (nativo da a\xe7\xe3o oficial `actions/cache`) retornar\xe1 `false`. Assim, o fluxo de trabalho vai executar a etapa de instala\xe7\xe3o.  \\n[*Confere nos logs!*](https://raw.githubusercontent.com/magmanu/blog/main/demos/github-actions-data-flow/31_data_flow_cache_set-cache.txt) (em ingl\xeas)  \\n\\nMaaaas... Uma pequena m\xe1gica tamb\xe9m acontece: uma etapa p\xf3s-cache, adicionada automaticamente pela a\xe7\xe3o `action/cache` no final da execu\xe7\xe3o do trabalho, confere as chaves e adiciona os arquivos ao cache.  \\n\\n\\n### Recuperando o cache\\n\\nDesde que nada tenha mudado no manifesto das depend\xeancias (requirements.txt), quando `actions/cache` for executado de novo com o mesmo caminho e a mesma chave, a a\xe7\xe3o vai encontrar um `cache-hit` e o fluxo de trabalho vai pular a etapa de instala\xe7\xe3o.  \\n[*Confere nos logs!*](https://raw.githubusercontent.com/magmanu/blog/main/demos/github-actions-data-flow/32_data_flow_cache_use-cache.txt) (em ingl\xeas)  \\n\\n### Atualizando o cache\\n\\nVoc\xea reparou na fun\xe7\xe3o `hashFiles` usada no argumento `key`?  \\nEsta \xe9 uma fun\xe7\xe3o nativa do GitHub Actions que cria uma hash exclusiva baseada no caminho de um arquivo. Quando o valor da hash n\xe3o d\xe1 match, significa que o arquivo foi alterado \u2013 no nosso caso, isso pode indicar que alguma depend\xeancia foi adicionada/removida/atualizada.  \\n\\nAssim, o cache fica in\xfatil, e o output `cache-hit` vai induzir a execu\xe7\xe3o de `pip install`. Voltamos ent\xe3o \xe0 \xe0 estaca zero: as depend\xeancias s\xe3o instaladas mais uma vez e o cache \xe9 atualizado.  \\n[*Confere nos logs!*](https://raw.githubusercontent.com/magmanu/blog/main/demos/github-actions-data-flow/33_data_flow_cache_update-cache.txt) (em ingl\xeas)  \\n\\n### Coment\xe1rios finais sobre caches\\n\\n- A op\xe7\xe3o de auto-armazenar o cache em executores auto-hospedados s\xf3 est\xe1 dispon\xedvel nos planos Enterprise.\\n- A a\xe7\xe3o `actions/cache` gerencia o cache de forma centralizada. Isso significa que o cache fica dispon\xedvel e atualiz\xe1vel para todos os trabalhos no mesmo repo - e at\xe9 mesmo para outros fluxos de trabalho.\\n- Leia mais sobre [estrat\xe9gias de cache aqui](https://github.com/actions/cache/blob/main/caching-strategies.md) (em ingl\xeas).\\n\\n\\nEita que post grande, socorro."},{"id":"dynamic-json-in-terraform","metadata":{"permalink":"/blog/pt-BR/tech/dynamic-json-in-terraform","source":"@site/i18n/pt-BR/docusaurus-plugin-content-blog-tech/2023-03-18-dynamic-json-in-terraform/index.md","title":"Como Gerar JSON Din\xe2mico no Terraform","description":"Quem programa n\xe3o se aguenta, n\xe9? N\xe3o pode ver uma coisinha declarativa que j\xe1 quer fazer um loop, colocar uma l\xf3gica, faz qualquer coisa menos... declara\xe7\xe3o.","date":"2023-03-18T00:00:00.000Z","tags":[{"label":"infra","permalink":"/blog/pt-BR/tech/tags/infra"},{"label":"terraform","permalink":"/blog/pt-BR/tech/tags/terraform"},{"label":"IaC","permalink":"/blog/pt-BR/tech/tags/ia-c"},{"label":"step functions","permalink":"/blog/pt-BR/tech/tags/step-functions"},{"label":"devops","permalink":"/blog/pt-BR/tech/tags/devops"}],"readingTime":8.91,"hasTruncateMarker":true,"authors":[{"name":"Manu Magalh\xe3es","title":"Engenheira de DevSecOps","url":"https://github.com/magmanu","imageURL":"https://github.com/magmanu.png","key":"manu"}],"frontMatter":{"slug":"dynamic-json-in-terraform","title":"Como Gerar JSON Din\xe2mico no Terraform","authors":"manu","tags":["infra","terraform","IaC","step functions","devops"]},"unlisted":false,"prevItem":{"title":"GitHub Actions: Fluxo e Persist\xeancia de Dados em Workflows","permalink":"/blog/pt-BR/tech/github-actions-data-flow"},"nextItem":{"title":"Solu\xe7\xe3o: Terraform n\xe3o deixa tern\xe1rios terem tipos diferentes","permalink":"/blog/pt-BR/tech/terraform-ternary-error"}},"content":"Quem programa n\xe3o se aguenta, n\xe9? N\xe3o pode ver uma coisinha declarativa que j\xe1 quer fazer um loop, colocar uma l\xf3gica, faz qualquer coisa menos... declara\xe7\xe3o.\\n\\nAqui vou mostrar como gerar um JSON din\xe2mico no Terraform. Neste artigo vou usar Step Functions como exemplo, mas voc\xea pode usar o JSON que quiser.\\n\\n## O que vamos fazer\\n\\nO JSON abaixo vai sofrer uma transforma\xe7\xe3o. Vamos substituir os valores est\xe1ticos por:\\n\\n1. [Uma vari\xe1vel](#caso-1-injetando-uma-vari\xe1vel-no-json)\\n2. [Uma lista din\xe2mica](#caso-2-injetando-uma-lista-no-json)\\n3. [Um ou mais objetos din\xe2micos](#caso-3-injetando-um-objeto-no-json)\\n\\n\x3c!--truncate--\x3e\\n\\n(Adicionei coment\xe1rios n\xe3o idiom\xe1ticos dentro do c\xf3digo, mas \xe9 s\xf3 para deixar bem claro o que estamos fazendo.)\\n\\n```json title=\'JSON de refer\xeancia\'\\n{\\n    \\"Comment\\": \\"My state machine\\",\\n    \\"StartAt\\": \\"Choice\\",\\n    \\"States\\": {\\n        \\"Handle Notification\\": {\\n            \\"Type\\": \\"Task\\",\\n            \\"Resource\\": \\"arn:aws:states:::lambda:invoke\\",\\n            \\"OutputPath\\": \\"$.Payload\\",\\n            \\"Parameters\\": {\\n              \\"Payload.$\\": \\"$\\",\\n              // highlight-start\\n              ----\x3e Caso 1: Substituir a string expl\xedcita por uma string din\xe2mica\\n              \\"FunctionName\\": \\"my_function_name\\"\\n              // highlight-end\\n            },\\n            \\"End\\": true\\n        },\\n        \\"Choice\\": {\\n          \\"Type\\": \\"Choice\\",\\n           // highlight-start\\n          ----\x3e Caso 2: Substituir por uma lista din\xe2mica\\n          \\"Choices\\": [                          \\n             {                                           \\n               \\"IsPresent\\": true,                        \\n               \\"Next\\": \\"SSM Execution-InstanceId\\",       \\n               \\"Variable\\": \\"$.InstanceId\\"                \\n              },                                         \\n              {                                          \\n               \\"IsPresent\\": true,                        \\n               \\"Next\\": \\"SSM Execution-SecurityGroupIds\\", \\n               \\"Variable\\": \\"$.SecurityGroupIds\\"          \\n              }                                          \\n            ],                                   \\n            // highlight-end\\n            \\"Default\\": \\"Pass\\"\\n        },\\n        // highlight-start\\n        ----\x3e Caso 3: Substituir por um ou mais objetos din\xe2micos\\n        \\"SSM Execution-InstanceId\\": {        \\n            \\"Next\\": \\"Pass\\",                          \\n            \\"Parameters\\": {                          \\n                \\"DocumentName.$\\": \\"$.DocumentName\\",  \\n                \\"Parameters\\": {                      \\n                    \\"InstanceId.$\\": \\"States.Array($.InstanceId)\\"\\n                }                                    \\n              },                                     \\n            \\"Resource\\": \\"arn:aws:states:::aws-sdk:ssm:startAutomationExecution\\",\\n            \\"ResultPath\\": \\"$.TaskResult\\",            \\n            \\"Type\\": \\"Task\\"                           \\n        },                                           \\n        \\"SSM Execution-SecurityGroupIds\\": {          \\n            \\"Next\\": \\"Pass\\",                          \\n            \\"Parameters\\": {                          \\n                \\"DocumentName.$\\": \\"$.DocumentName\\",  \\n                \\"Parameters\\": {                      \\n                    \\"SecurityGroupIds.$\\": \\"States.Array($.SecurityGroupIds)\\"\\n                }                                    \\n            },                                       \\n            \\"Resource\\": \\"arn:aws:states:::aws-sdk:ssm:startAutomationExecution\\",\\n            \\"ResultPath\\": \\"$.TaskResult\\",            \\n            \\"Type\\": \\"Task\\"                           \\n        },                                   \\n        // highlight-end\\n        \\"Pass\\": {\\n            \\"Type\\": \\"Pass\\",\\n            \\"End\\": true\\n        }\\n    }\\n}\\n```\\n\\nPrimeiro, salve o JSON acima em formato de template. Voc\xea pode usar a extens\xe3o `.tpl` ou `.tftpl`. Embora o Terraform recomende usar a segunda op\xe7\xe3o, n\xe3o existe uma regra r\xedgida sobre qual extens\xe3o usar.\\n\\n## Caso 1: Injetando uma vari\xe1vel no JSON\\n\\nVamos come\xe7ar atualizando o valor `FunctionName` no template, usando interpola\xe7\xe3o:\\n\\n```json title=\'modules/templates/stepfunction_definition.tftpl (parcial)\'\\n\\n{\\"Handle Notification\\": {\\n        \\"Type\\": \\"Task\\",\\n        \\"Resource\\": \\"arn:aws:states:::lambda:invoke\\",\\n        \\"OutputPath\\": \\"$.Payload\\",\\n        \\"Parameters\\": {\\n          \\"Payload.$\\": \\"$\\",\\n          // highlight-next-line\\n          \\"FunctionName\\": \\"${nome_da_lambda}\\"\\n        },\\n        \\"End\\": true\\n      }\\n}\\n```\\n\\nO template precisa ser renderizado como um JSON v\xe1lido, ent\xe3o vamos usar a fun\xe7\xe3o `templatefile` do Terraform. Pra isso, usamos dois argumentos: o caminho (path) do template e um mapa de vari\xe1veis a serem injetadas na runtime (execu\xe7\xe3o). Vou tentar manter o m\xf3dulo o mais din\xe2mico poss\xedvel, e vou incluir locals, vari\xe1veis e resources (recursos) do Terraform para mostrar como as coisas funcionam juntas.\\n\\n```hcl title=\'modules/stepfunction.tf (full file)\'\\n\\nlocals {\\n    file = templatefile(\\"${path.module}/templates/stepfunction_definition.tpl\\", {\\n        nome_da_lambda = var.nome_da_lambda\\n    })\\n}\\nvariable \\"nome_da_lambda\\" {\\n    description = \\"Nome da lambda\\"\\n    type        = string\\n}\\n\\nresource \\"aws_sfn_state_machine\\" \\"sfn_state_machine\\" {\\n    name        = var.nome_da_step_function\\n    role_arn    = var.sf_role_arn\\n    definition  = local.file\\n}\\n```\\n\\nAgora vamos salvar um `main.tf` um n\xedvel acima, onde os valores expl\xedcitos (hardcoded) ser\xe3o definidos.\\n\\n```hcl title=\'main.tf (full file)\'\\n\\n# main.tf (arquivo completo)\\n\\nmodule \\"minha_step_function\\" {\\n  source                = \\"./modules/step_functions\\"\\n  nome_da_step_function    = \\"autoremedia\xe7\xe3o\\"\\n  sf_role_arn           = \\"arn:aws:iam::123456789012:role/autoremedia\xe7\xe3o\\"\\n  nome_da_lambda  = \\"lambda_de_autoremedia\xe7\xe3o\\"\\n}\\n```\\n\\nSe quiser conferir que a vari\xe1vel foi injetada com sucesso, execute `terraform init && terraform plan` no terminal.\\n\\n## Caso 2: Injetando uma lista no JSON\\n\\nS\xf3 pra lembrar, esta \xe9 a lista que estamos refatorando:\\n\\n```json title=\'modules/templates/stepfunction_definition.tftpl (parcial)\'\\n\\n\\"Choice\\": {\\n    \\"Type\\": \\"Choice\\",\\n    // highlight-start\\n    \\"Choices\\": [                            \\n        {                                           \\n          \\"IsPresent\\": true,                        \\n          \\"Next\\": \\"SSM Execution-InstanceId\\",       \\n          \\"Variable\\": \\"$.InstanceId\\"                \\n        },                                          \\n        {                                           \\n          \\"IsPresent\\": true,                        \\n          \\"Next\\": \\"SSM Execution-SecurityGroupIds\\", \\n          \\"Variable\\": \\"$.SecurityGroupIds\\"          \\n        }                                           \\n    ],                                      \\n    // highlight-end\\n    \\"Default\\": \\"Pass\\"\\n}\\n```\\n\\nVamos refatorar o template de novo. Vamos usar uma fun\xe7\xe3o do Terraform chamada `jsonencode`, que faz a lista de objetos usada no template ser renderizada como JSON:\\n\\n```json title=\'modules/templates/stepfunction_definition.tftpl (parcial)\'\\n\\n\\"Choice\\": {\\n    \\"Type\\": \\"Choice\\",\\n    // highlight-next-line\\n    \\"Choices\\": ${jsonencode(lista_de_op\xe7\xf5es)},\\n    \\"Default\\": \\"Pass\\"\\n    }\\n ```\\n\\nAgora, vamos ver duas maneiras de passar a lista para o template.\\n\\n### A solu\xe7\xe3o mais simples: lista expl\xedcita\\n\\nUma op\xe7\xe3o \xe9 criar uma vari\xe1vel que vai passar uma lista pronta:\\n\\n```hcl title=\'modules/stepfunction.tf (pacial)\'\\n\\nlocals {\\n    file = templatefile(\\"${path.module}/templates/stepfunction_definition.tpl\\", {\\n        nome_da_lambda = var.nome_da_lambda\\n        // highlight-next-line\\n        lista_de_op\xe7\xf5es = var.minha_lista\\n    })\\n}\\n// highlight-start\\nvariable \\"minha_lista\\" {\\n    description = \\"A lista que voc\xea quiser\\"\\n    type = list\\n// highlight-end\\n}\\n```\\n\\nAgora, no m\xf3dulo `main.tf`, passe os valores das vari\xe1veis. O JSON ficou \xe9 din\xe2mico, mas a lista \xe9 ainda \xe9 meio \u201cest\xe1tica\u201d porque foi definida explicitamente no m\xf3dulo principal. E v\xe1rias vezes, isso basta.\\n\\n```hcl title=\'main.tf (full file)\'\\n\\nmodule \\"minha_step_function\\" {\\n    source                = \\"./modules/step_functions\\"\\n    nome_da_step_function    = \\"autoremedia\xe7\xe3o\\"\\n    sf_role_arn           = \\"arn:aws:iam::123456789012:role/autoremedia\xe7\xe3o\\"\\n    nome_da_lambda  = \\"lambda_de_autoremedia\xe7\xe3o\\"\\n\\n    // highlight-start\\n    minha_lista = [{\\n        \\"IsPresent\\": true,\\n        \\"Next\\": \\"SSM Execution-InstanceId\\",\\n        \\"Variable\\": \\"$.InstanceId\\"\\n    }]\\n    // highlight-end\\n}\\n```\\n\\n### A solu\xe7\xe3o com muita l\xf3gica: lista din\xe2mica\\n\\nMas e se voc\xea quiser que a lista em si tamb\xe9m seja din\xe2mica? Por exemplo, voc\xea quer gerar a lista extraindo os valores de um par\xe2metro, e depois enviar a lista para o json?\\nEm nosso exemplo, vamos gerar as listas de `Next` e `Variable` extraindo as chaves (keys) que est\xe3o em `ssm_params`, no arquivo principal `main.tf`:\\n\\n```hcl title=\'main.tf (extract)\'\\n\\nmodule \\"minha_step_function\\" {\\n    source                = \\"./modules/step_functions\\"\\n    nome_da_step_function    = \\"autoremedia\xe7\xe3o\\"\\n    sf_role_arn           = \\"arn:aws:iam::123456789012:role/autoremedia\xe7\xe3o\\"\\n    nome_da_lambda  = \\"lambda_de_autoremedia\xe7\xe3o\\"\\n\\n    // highlight-start\\n    # Tiramos a lista est\xe1tica que estava aqui\\n    ssm_params = [\\n        {\\"InstanceId\\": \\"States.Array($.InstanceId)\\"},    \\n        {\\"SecurityGroupIds\\": \\"States.Array($.SecurityGroupIds)\\"}\\n    ]\\n    // highlight-end\\n}\\n```\\n\\nNosso m\xf3dulo vai ficar assim:\\n\\n```hcl title=\'modules/stepfunction.tf (full file)\'\\n\\nlocals {\\n    lista_de_op\xe7\xf5es = flatten([for item in var.ssm_params: [\\n        for chave, valor in item : {\\n            \\"IsPresent\\": true,\\n            \\"Next\\": \\"SSM Execution-${chave}\\"\\n            \\"Variable\\": \\"$.${chave}\\",\\n        }]\\n    ])\\n    file = templatefile(\\"${path.module}/templates/stepfunction_definition.tpl\\", {\\n        nome_da_lambda = var.nome_da_lambda,\\n        lista_de_op\xe7\xf5es = local.lista_de_op\xe7\xf5es\\n    })\\n}\\n\\nvariable \\"nome_da_lambda\\" {\\n    description = \\"Nome da lambda\\"\\n    type        = string\\n}\\n\\nvariable \\"ssm_params\\" {\\n    description = \\"Lista dos par\xe2metros de SSM a serem injetados\\"\\n    type = list\\n}\\n\\nresource \\"aws_sfn_state_machine\\" \\"sfn_state_machine\\" {\\n    name        = var.nome_da_step_function\\n    role_arn    = aws_iam_role.step_function_role_arn\\n    definition  = local.file\\n}\\n```\\n\\nCome\xe7ando com a linha `lista_de_op\xe7\xf5es = flatten([for item in var.ssm_params:` ignore `flatten` por um momento e observe o loop. \\n\\n`ssm_params` \xe9 uma lista, e vamos ver cada item. O loop est\xe1 entre colchetes, o que significa que o resultado ser\xe1 uma lista. O `:` que se segue \xe9 apenas parte da sintaxe do loop.\\n\\nNa linha a seguir, temos outro loop: `for chave, valor in item : {` . Este loop passa em cada objeto do `ssm_params`, acessando a chave e o valor. Assim, podemos extrair e reestruturar os dados. O loop tamb\xe9m \xe9 colocado entre colchetes, o que significa que, infelizmente, cada objeto estar\xe1 dentro de uma lista pr\xf3pria. O resultado final vai ficar assim: `[[obj1],[obj2]]`\\n\\nAgora, lembra do `flatten`? Essa fun\xe7\xe3o do Terraform \xe9 necess\xe1ria porque precisamos achatar (flatten) esse resultado que est\xe1 cheio de aninhamento (nesting) desnecess\xe1rio. O flatten faz nosso resultado ficar assim: `[obj1, obj2]`.\\n\\nPronto.\\n\\n## Caso 3: Injetando um objeto no JSON\\n\\nAgora, a parte mais emocionante. Vamos abstrair objetos inteiros. (Neste caso, significa que etapas inteiras das Step Functions podem ficar din\xe2micas!)\\nT\xe1 vendo isso tudo a\xed embaixo? Vai tudo embora!\\n\\n```json\\n\\"Steps\\": {\\n    // highlight-start\\n    \\"SSM Execution-InstanceId\\": {           \\n            \\"Next\\": \\"Pass\\",                          \\n            \\"Parameters\\": {                          \\n                \\"DocumentName.$\\": \\"$.DocumentName\\",  \\n                \\"Parameters\\": {                      \\n                    \\"InstanceId.$\\": \\"States.Array($.InstanceId)\\"\\n                }                                    \\n              },                                     \\n            \\"Resource\\": \\"arn:aws:states:::aws-sdk:ssm:startAutomationExecution\\",\\n            \\"ResultPath\\": \\"$.TaskResult\\",            \\n            \\"Type\\": \\"Task\\"                           \\n        },                                           \\n        \\"SSM Execution-SecurityGroupIds\\": {          \\n            \\"Next\\": \\"Pass\\",                          \\n            \\"Parameters\\": {                          \\n                \\"DocumentName.$\\": \\"$.DocumentName\\",  \\n                \\"Parameters\\": {                      \\n                    \\"SecurityGroupIds.$\\": \\"States.Array($.SecurityGroupIds)\\"\\n                }                                    \\n            },                                       \\n            \\"Resource\\": \\"arn:aws:states:::aws-sdk:ssm:startAutomationExecution\\",\\n            \\"ResultPath\\": \\"$.TaskResult\\",            \\n            \\"Type\\": \\"Task\\"                           \\n        }                                   \\n        // highlight-end\\n}\\n```\\n\\nPra variar, vamos modificar o template:\\n\\n```hcl title=\'modules/templates/stepfunction_definition.tftpl (parcial)\'\\n\\n\\"States\\": {\\n    \\"Choice\\": {\\n      \\"Type\\": \\"Choice\\",\\n      \\"Choices\\": ${jsonencode(choices)},\\n      \\"Default\\": \\"Pass\\"\\n    },\\n    / highlight-start\\n    %{ for chave, data in ssm_execution }   \\n        \\"${chave}\\": ${jsonencode(data)},\\n    %{ endfor }\\n    \\"Handle Notification\\": {<--- bl\xe1bl\xe1--\x3e}\\n    }\\n    // highlight-end\\n```\\n\\nSe seu linter reclamar, mantenha a f\xe9 que t\xe1 tudo certo.  \\n\\nMas o que est\xe1 acontecendo? Estamos usando a sintaxe [diretiva do Terraform](https://developer.hashicorp.com/terraform/language/expressions/strings#directives) `%{}` para escrever uma string din\xe2mica (pois \xe9, templates s\xe3o tratados como strings) .\\n\\nA linha `%{ for chave, data in ssm_execution }` informa \xe0 fun\xe7\xe3o `templatefile` que uma itera\xe7\xe3o vai come\xe7ar, e que cs\xf3 termina quando chegar na linha `%{ endfor }`. Enquanto isso, a fun\xe7\xe3o vai ontinuar criando pares de chave-valor com o formato `\\"minha_chave\\": {\\"meu\\": \\"json\\"},`.\\n\\nLegal, n\xe9?\\n\\nEnt\xe3o agora vamos adicionar o valor local `ssm_execution`, a l\xf3gica que ir\xe1 preencher tudo isso.\\n\\n```hcl title=\'modules/stepfunction.tf (parcial)\'\\n\\nlocals {\\n    choices = flatten([for item in var.ssm_params: [\\n        for chave, valor in item : {\\n            \\"IsPresent\\": true,\\n            \\"Next\\": \\"SSM Execution-${chave}\\"\\n            \\"Variable\\": \\"$.${chave}\\",\\n        }]\\n    ])\\n\\n    // highlight-start\\n    ssm_execution = merge(flatten([for item in var.ssm_params: [ \\n                    for chave, valor in item : {\\n                        \\"SSM Execution-${chave}\\": {\\n                            \\"Type\\": \\"Task\\",\\n                            \\"Parameters\\": {\\n                              \\"DocumentName.$\\": \\"$.DocumentName\\",\\n                              \\"Parameters\\": {\\"$.${chave}\\": \\"${valor}\\"}\\n                            },\\n                            \\"Resource\\": \\"arn:aws:states:::aws-sdk:ssm:startAutomationExecution\\",\\n                            \\"Next\\": \\"Handle Notification\\",\\n                            \\"ResultPath\\": \\"$.TaskResult\\"\\n                        }\\n                    }\\n                    ]]\\n                )...)\\n    // highlight-end\\n\\n    file = templatefile(\\"${path.module}/templates/stepfunction_definition.tpl\\", {\\n        nome_da_lambda = var.nome_da_lambda,\\n        lista_de_op\xe7\xf5es = local.choices,\\n        // highlight-next-line\\n        ssm_execution = local.ssm_execution\\n    })\\n}\\n```\\n\\nJ\xe1 estamos familiarizados com loops e flatten, ent\xe3o vamos falar sobre as novidades: `merge` e `...`.\\n\\n`merge` \xe9 uma fun\xe7\xe3o do Terraform que junta v\xe1rios objetos em um s\xf3. Ent\xe3o, se tivermos dois objetos assim:\\n\\n```json\\n   {\\n     \\"a\\": 1,\\n     \\"b\\": 2\\n   },\\n   {\\n     \\"c\\": 3,\\n     \\"d\\": 4\\n   }\\n```\\n\\na fun\xe7\xe3o `merge` vai transform\xe1-los em:\\n\\n```json\\n{\\n     \\"a\\": 1,\\n     \\"b\\": 2,\\n     \\"c\\": 3,\\n     \\"d\\": 4\\n}\\n```\\n\\nE se voc\xea estava prestando aten\xe7\xe3o, notou que a fun\xe7\xe3o merge em nosso m\xf3dulo **n\xe3o** est\xe1 usando objetos como argumento, ela est\xe1 usando a fun\xe7\xe3o flatten (que gera uma \xfanica lista). O truque est\xe1 aqui: `...`.\\n\\nNo Terraform, `...` (tr\xeas pontos) funciona como o operador spread em Javascript: ele expande a lista em argumentos separados, individuais.\\n\\nEnt\xe3o \xe9 isso. Nosso template final ficou literalmente com metade do tamanho do JSON original. Ele \xe9 din\xe2mico, reutiliz\xe1vel e o melhor de tudo \u2013 voc\xea nunca mais vai precisar o Amazon States Language no seu projeto. Vale cada minuto investido.\\n\\n## Arquivos Finais\\n\\n```hcl title=\'modules/templates/stepfunction_definition.tpl\'\\n\\n{\\n    \\"Comment\\": \\"My state machine\\",\\n    \\"StartAt\\": \\"Choice\\",\\n    \\"States\\": {\\n        \\"Handle Notification\\": {\\n            \\"Type\\": \\"Task\\",\\n            \\"Resource\\": \\"arn:aws:states:::lambda:invoke\\",\\n            \\"OutputPath\\": \\"$.Payload\\",\\n            \\"Parameters\\": {\\n              \\"Payload.$\\": \\"$\\",\\n              \\"FunctionName\\": \\"${nome_da_lambda}\\"\\n            },\\n            \\"End\\": true\\n        },\\n        \\"Choice\\": {\\n            \\"Type\\": \\"Choice\\",\\n            \\"Choices\\": ${jsonencode(choices)},\\n            \\"Default\\": \\"Pass\\"\\n        },\\n        %{ for chave, data in ssm_execution }\\n        \\"${chave}\\": ${jsonencode(data)},\\n        %{ endfor }\\n        \\"Pass\\": {\\n            \\"Type\\": \\"Pass\\",\\n            \\"End\\": true\\n        }\\n    }\\n}\\n```\\n\\n```hcl title=\'modules/stepfunction.tf\'\\nlocals {\\n    choices = flatten([for item in var.ssm_params: [\\n        for chave, valor in item : {\\n            \\"IsPresent\\": true,\\n            \\"Next\\": \\"SSM Execution-${chave}\\"\\n            \\"Variable\\": \\"$.${chave}\\",\\n        }]\\n    ])\\n\\n    ssm_execution = merge(flatten([for item in var.ssm_params: [ \\n                    for chave, valor in item : {\\n                        \\"SSM Execution-${chave}\\": {\\n                            \\"Type\\": \\"Task\\",\\n                            \\"Parameters\\": {\\n                              \\"DocumentName.$\\": \\"$.DocumentName\\",\\n                              \\"Parameters\\": {\\"$.${chave}\\": \\"${valor}\\"}\\n                            },\\n                            \\"Resource\\": \\"arn:aws:states:::aws-sdk:ssm:startAutomationExecution\\",\\n                            \\"Next\\": \\"Handle Notification\\",\\n                            \\"ResultPath\\": \\"$.TaskResult\\"\\n                        }\\n                    }\\n                    ]]\\n                )...)\\n\\n    file = templatefile(\\"${path.module}/templates/stepfunction_definition.tpl\\", {\\n        nome_da_lambda = var.nome_da_lambda,\\n        lista_de_op\xe7\xf5es = local.choices,\\n        ssm_execution = local.ssm_execution\\n    })\\n}\\n\\nvariable \\"nome_da_lambda\\" {\\n    description = \\"Nome da lambda\\"\\n    type        = string\\n}\\n\\nvariable \\"ssm_params\\" {\\n    description = \\"Lista dos par\xe2metros de SSM a serem injetados\\"\\n    type = list\\n}\\n\\nresource \\"aws_sfn_state_machine\\" \\"sfn_state_machine\\" {\\n    name        = var.nome_da_step_function\\n    role_arn    = var.sf_role_arn\\n    definition  = local.file\\n}\\n```\\n\\n```hcl title=\'main.tf\'\\n# main.tf (arquivo completo)\\n\\nmodule \\"minha_step_function\\" {\\n    source                = \\"./modules/step_functions\\"\\n    nome_da_step_function    = \\"autoremedia\xe7\xe3o\\"\\n    sf_role_arn           = \\"arn:aws:iam::123456789012:role/autoremedia\xe7\xe3o\\"\\n    nome_da_lambda  = \\"lambda_de_autoremedia\xe7\xe3o\\"\\n\\n    ssm_params = [                \\n        {\\"InstanceId\\": \\"States.Array($.InstanceId)\\"},    \\n        {\\"SecurityGroupIds\\": \\"States.Array($.SecurityGroupIds)\\"}\\n    ]\\n}\\n```"},{"id":"terraform-ternary-error","metadata":{"permalink":"/blog/pt-BR/tech/terraform-ternary-error","source":"@site/i18n/pt-BR/docusaurus-plugin-content-blog-tech/2023-03-18-terraform-ternary-errors/index.md","title":"Solu\xe7\xe3o: Terraform n\xe3o deixa tern\xe1rios terem tipos diferentes","description":"Voc\xea j\xe1 encontrou esse erro no Terraform, quando o que voc\xea queria era exatamente ter tipos diferentes no resultado do tern\xe1rio?","date":"2023-03-18T00:00:00.000Z","tags":[{"label":"infra","permalink":"/blog/pt-BR/tech/tags/infra"},{"label":"terraform","permalink":"/blog/pt-BR/tech/tags/terraform"},{"label":"gambiarra","permalink":"/blog/pt-BR/tech/tags/gambiarra"},{"label":"devops","permalink":"/blog/pt-BR/tech/tags/devops"}],"readingTime":2.65,"hasTruncateMarker":true,"authors":[{"name":"Manu Magalh\xe3es","title":"Engenheira de DevSecOps","url":"https://github.com/magmanu","imageURL":"https://github.com/magmanu.png","key":"manu"}],"frontMatter":{"slug":"terraform-ternary-error","title":"Solu\xe7\xe3o: Terraform n\xe3o deixa tern\xe1rios terem tipos diferentes","authors":"manu","tags":["infra","terraform","gambiarra","devops"]},"unlisted":false,"prevItem":{"title":"Como Gerar JSON Din\xe2mico no Terraform","permalink":"/blog/pt-BR/tech/dynamic-json-in-terraform"},"nextItem":{"title":"Como Migrar do CodeCommit para o GitHub \u2014 Mantendo sua pipeline Amplify","permalink":"/blog/pt-BR/tech/migrate-codecommit-to-github"}},"content":"Voc\xea j\xe1 encontrou esse erro no Terraform, quando o que voc\xea queria era exatamente ter tipos diferentes no resultado do tern\xe1rio?\\n\\n>The true and false result expressions must have consistent types  \\n> *Express\xf5es com resultado true ou false devem ter tipos consistentes*\\n\\nVou dar dois exemplos de como contornar esse problema, mas a regra geral \xe9 esta aqui:\\n\\n\\n```hcl\\natributo = [\\n    <valor caso true>, \\n    <valor caso false>\\n    ][<condicional> ? 0 : 1]\\n```\\n\\n\x3c!--truncate--\x3e\\n\\n## Exemplo simples\\n\\n```hcl\\nlocals {\\n    valor_dinamico = [\\n      {\\"regiao\\": \\"${var.regiao}\\"}, \\n      \\"indispon\xedvel\\"\\n      ][var.regiao == \\"eu-west-1\\" ? 0 : 1 ]\\n}\\n```\\n\\nNo exemplo acima, `local.valor_dinamico` vai ser avaliado como `{\\"regiao: \\"eu-west-1\\"}`, que \xe9 um `objeto`, se a regi\xe3o da AWS for a Irlanda; e retorna `\\"indispon\xedvel\\"`, que \xe9 uma `string`, se for alguma outra regi\xe3o.\\n\\n### Pera, como \xe9 que \xe9?\\n\\nEm vez de usar o tern\xe1rio da maneira tradicional, n\xf3s usamos uma tupla (tamb\xe9m conhecida como lista com tipos mistos) e aproveitamos a estrutura do tern\xe1rio para avaliar qual \xedndice cont\xe9m o valor de que precisamos.\\n\\nNo fundo, estamos selecionando se queremos o primeiro ou segundo valor que est\xe1 na tupla, como se fosse  `tupla[0]` ou `tupla[1]`.\\n\\nObrigada Mariux pelo truque.\\n\\n## Um exemplo menos simples\\n\\nTamb\xe9m d\xe1 pra fazer coisas mais complexas e din\xe2micas. N\xe3o estou dizendo fica bonito ou que seja recomend\xe1vel, mas \xe0s vezes a gente faz o que tem que ser feito.\\n\\nNo meu caso, a l\xf3gica tern\xe1ria que eu precisava era usada em uma Step Function. Eu tinha um objeto, e se esse objeto tivesse s\xf3 uma chave (key), eu precisava de um JSON. Se o objeto tivesse mais do que uma chave, eu precisava de um JSON diferente. \\n\\nA coisa fica meio feia porque tem l\xf3gica em tudo quanto \xe9 lugar, mas aqui vai o resultado:\\n\\n```hcl\\nvariable \\"ssm_params\\" {\\n    description = \\"Par\xe2metro exigido pelo SSM Documents para ativar rota\xe7\xe3o de chaves KMS\\"\\n    default     = [{\\"KeyId\\": \\"States.Array($.KeyId)\\",\\n                    \\"AutomationAssumeRole\\": \\"States.Array($.AutomationAssumeRole)\\"}]\\n}\\n\\nlocals {\\n  choices = [for item in var.ssm_params: [\\n    # valor caso true \\n    merge(flatten([\\n      for key, value in item: {\\n        \\"IsPresent\\": true,\\n        \\"Next\\": \\"SSM-${key}\\",\\n        \\"Variable\\": \\"$.${key}\\"\\n      }\\n    ])...), \\n    #\xa0valor caso false\\n    merge([\\n      { \\"And\\" : [\\n          for key, value in item: \\n            {\\n              \\"IsPresent\\": true,\\n              \\"Variable\\": \\"$.${key}\\"\\n            }\\n        ],\\n      \\"Next\\": \\"SSM-${join(\\"\\", sort([keys(item)]...))}\\"\\n      }\\n    ]...)\\n    ][\\n      # condicional\\n      length(flatten([keys(item)])) == 1 ? 0 : 1\\n      ]\\n  ]\\n}\\n```\\n\\nMinha tupla tem dois valores, os dois come\xe7am com `merge` e resultam em um array de objetos com valores gerados dinamicamente. E como d\xe1 pra ver, a estrutura dos objetos \xe9 diferente em cada caso, e \xe9 por isso que a solu\xe7\xe3o padr\xe3o para tern\xe1rios n\xe3o funciona.\\n\\nA seguir, a parte do condicional tamb\xe9m \xe9 din\xe2mica. A gente extrai as chaves do objeto, coloca as chaves em um \xfanico array usando `flatten` e avalia o tamanho do array. Se s\xf3 houver um elemento, o resultado final ser\xe1 o primeiro valor da tupla. Caso contr\xe1rio, o resultado final ser\xe1 o segundo valor da tupla.\\n\\nN\xe3o me pergunte como eu n\xe3o joguei o computador pela janela, mas funcionou. S\xf3 que eu nunca mais quero fazer uma coisa dessas. Se uma linguagem \xe9 declarativa n\xe3o era pra ter l\xf3gica complexa, n\xe9. Enfim. :P"},{"id":"migrate-codecommit-to-github","metadata":{"permalink":"/blog/pt-BR/tech/migrate-codecommit-to-github","source":"@site/i18n/pt-BR/docusaurus-plugin-content-blog-tech/2021-10-13-migrate-codecommit-to-github/index.md","title":"Como Migrar do CodeCommit para o GitHub \u2014 Mantendo sua pipeline Amplify","description":"Este tutorial inclui orienta\xe7\xf5es para tr\xeas cen\xe1rios de administra\xe7\xe3o no GitHub:","date":"2021-10-13T00:00:00.000Z","tags":[{"label":"infra","permalink":"/blog/pt-BR/tech/tags/infra"},{"label":"github","permalink":"/blog/pt-BR/tech/tags/github"},{"label":"amplify","permalink":"/blog/pt-BR/tech/tags/amplify"},{"label":"aws","permalink":"/blog/pt-BR/tech/tags/aws"},{"label":"ci/cd","permalink":"/blog/pt-BR/tech/tags/ci-cd"},{"label":"tutorial","permalink":"/blog/pt-BR/tech/tags/tutorial"}],"readingTime":4.9,"hasTruncateMarker":true,"authors":[{"name":"Manu Magalh\xe3es","title":"Engenheira de DevSecOps","url":"https://github.com/magmanu","imageURL":"https://github.com/magmanu.png","key":"manu"}],"frontMatter":{"slug":"migrate-codecommit-to-github","title":"Como Migrar do CodeCommit para o GitHub \u2014 Mantendo sua pipeline Amplify","authors":"manu","tags":["infra","github","amplify","aws","ci/cd","tutorial"]},"unlisted":false,"prevItem":{"title":"Solu\xe7\xe3o: Terraform n\xe3o deixa tern\xe1rios terem tipos diferentes","permalink":"/blog/pt-BR/tech/terraform-ternary-error"}},"content":"Este tutorial inclui orienta\xe7\xf5es para tr\xeas cen\xe1rios de administra\xe7\xe3o no GitHub:\\n\\n1. Quando o repo est\xe1 na sua conta pessoal;\\n2. Quando o repo est\xe1 dentro de uma organiza\xe7\xe3o no GitHub e a galera da administra\xe7\xe3o te d\xe1 as permiss\xf5es necess\xe1rias; e\\n3. Quando o repo est\xe1 dentro de uma organiza\xe7\xe3o no GitHub e a galera da administra\xe7\xe3o N\xc3O te d\xe1 as permiss\xf5es necess\xe1rias.\\n\\n_Pr\xe9-requisitos: Acesso e permiss\xf5es relevantes para CodeCommit e Amplify. Voc\xea tamb\xe9m precisa de uma conta ativa no GitHub._\\n\\n\x3c!--truncate--\x3e\\n\\n## Migrando o Repo\\n\\n1. Abra o terminal e fa\xe7a cd para a pasta onde est\xe1 o repo do CodeCommit.\\n2. Execute `git remote get-url origin` para obter o URL para clonar o projeto a ser migrado para o GitHub.\\n3. Crie uma pasta tempor\xe1ria executando `mkdir ../temp-clone` e abra-a na CLI executando `cd ../temp-clone`.\\n4. Execute `git clone --bare` seguido do URL que voc\xea pegou na etapa 2. Um exemplo seria `git clone --bare <https://git-codecommit.eu-west-1.amazonaws.com/v1/repos/nome-do-diretorio-do-codecommit>`.\\n\\n<br/>\\n\\n:::note Nota Educativa\\n\\nO sufixo (flag) `--bare` \xe9 uma forma de clonar o repo cortando todos os v\xednculos com o remoto (CodeCommit, neste caso). Voc\xea ainda vai ter todos os branches, tags e tal, mas o repo clonado fica completamente independente do remoto.\\n\\n:::\\n\\n<br/>\\n\\n5. Crie um novo repo no GitHub. Para evitar problemas, n\xe3o adicione nenhum README, .gitignore nem nada. Depois de clicar em \u201cCreate repo\u201d (Criar repo), a \xfanica coisa a fazer \xe9 copiar o URL como mostrado abaixo. N\xe3o execute nenhum git init, n\xe3o fa\xe7a um commit inicial, nada. S\xf3 copia o link.\\n\\n<br/>\\n\\n![Git clone SSH](./clone_ssh.webp)\\n\\n<br/>\\n\\n6. Voltando ao terminal, execute `cd nome-do-diretorio-do-codecommit.git`, e depois fa\xe7a um push mirror seguido pelo URL que voc\xea obteve na etapa 5. No exemplo acima, o comando seria `git push --mirror <https://github.com/my-username/my-project.git>`.\\n\\n\xc9 isso, a migra\xe7\xe3o acabou.\\n\\n### Confirme\\n\\nPara confirmar que deu tudo certo, volte ao GitHub e atualize a p\xe1gina. O repo vai estar todo bonitinho l\xe1, com hist\xf3rico de commits, as branches e o resto todo.  \\nPara usar repo migrado para o GitHub, \xe9 s\xf3 fazer o clone de sempre e seguir com a vida :)\\n\\n### Arrume\\n\\nSe voc\xea seguiu as instru\xe7\xf5es, agora \xe9 hora de excluir sua pasta tempor\xe1ria. Volte para o terminal e execute `cd ../..` e `rm -rf temp-clone`. Se voc\xea usou a pasta tmp do sistema operacional, pode pular essa etapa.\\n\\n\\n## Redirecionando a pipeline do Amplify\\n\\nAgora que voc\xea migrou o c\xf3digo para o GitHub, como voc\xea mant\xe9m a pipeline Amplify que estava ligada ao repo no CodeCommit?\\n\\n### Execute o comando `update-app`\\n```bash\\nAWS_PROFILE=PERFIL AWS_DEFAULT_REGION=REGI\xc3O aws amplify update-app --app-id AMPLIFY_APP_ID --repository REPOSITORY_URL --access-token ACCESS_TOKEN\\n```\\n\\n`AMPLIFY_APP_ID`: para encontrar a ID da sua aplica\xe7\xe3o, acesse o console do Amplify. Em App settings (Configura\xe7\xf5es do aplicativo), clique em General (Geral) e procure o ARN da aplica\xe7\xe3o. A ID da aplica\xe7\xe3o \xe9 a sequ\xeancia alfanum\xe9rica no final do ARN. A ID \xe9 mostrada como REDACTED na imagem abaixo:\\n\\n<br/>\\n\\n![Amplify App Id](./amplify_data.webp)\\n\\n<br/>\\n\\n`REPOSITORY_URL`: \xc9 o URL que voc\xea usou na etapa 5 da migra\xe7\xe3o.  \\n`ACCESS_TOKEN`: o token de acesso \xe9 um token que voc\xea pode gerar no GitHub. Pode ser o PAT (token de acesso pessoal) de quem administra o repo, mas se for um projeto profissional, prefira usar um [token de acesso do usu\xe1rio gerado por um app no GitHub](https://docs.github.com/pt/apps/creating-github-apps/authenticating-with-a-github-app/generating-a-user-access-token-for-a-github-app).\\n\\n### Reautentique o app Amplify\\n\\n:::tip XP da vida real\\n\\nAs empresas podem restringir bastante quais apps s\xe3o aprovados no GitHub. Se por algum motivo o app Amplify n\xe3o for aprovado, pule para a se\xe7\xe3o [\\"A abordagem via Webhook\\"](#a-abordagem-via-webhook).\\n:::\\n\\nAgora voc\xea pode reconectar sua aplica\xe7\xe3o. Na mesma p\xe1gina em que obteve o ARN, acima do ARN tem o bot\xe3o \u201cReconnect repository\u201d (Reconectar reposit\xf3rio). Ao clicar nele, a p\xe1gina de aprova\xe7\xe3o no GitHub \xe9 aberta.\\n\\n- **Se o reposit\xf3rio migrado N\xc3O estiver em uma Organiza\xe7\xe3o**, clique no bot\xe3o \u201cAuthorize aws-amplify-console\u201d (Autorizar aws-amplify-console). O console do Amplify vai abrir, e l\xe1 voc\xea pode selecionar o repo. Pronto, fim.\\n- **Se o reposit\xf3rio migrado estiver em uma Organiza\xe7\xe3o**, clique no bot\xe3o para solicitar a permiss\xe3o OAuth para o app Amplify. Uma mensagem de solicita\xe7\xe3o pendente fica dispon\xedvel at\xe9 que a administra\xe7\xe3o a aprove (voc\xea vai receber um e-mail quando isso acontecer).\\n\\n<br/>\\n\\n![Authorize Amplify Github App](./authorize_amplify_app.webp)\\n\\n<br/>\\n\\nDepois da aprova\xe7\xe3o, volte para o app Amplify e clique em \u201cReconnect repository\u201d (Reconectar reposit\xf3rio) novamente. Os repos da sua organiza\xe7\xe3o e da sua pr\xf3pria conta aparecem, para voc\xea escolher um deles. Fim.\\n\\n### A Abordagem via Webhook\\n\\nSe voc\xea n\xe3o puder usar o app Amplify no GitHub, voc\xea pode usar um webhook. Para isso, em App settings (Configura\xe7\xf5es do aplicativo), clique em General (Geral), selecione Build Settings (Configura\xe7\xf5es de compila\xe7\xe3o) e clique em Create Webhook (Criar Webhook),  ambos mostrados em laranja abaixo.\\n\\n<br/>\\n\\n![Amplify Build Settings](./amplify_build_settings.webp)\\n\\n<br/>\\n\\nNo pop-up, digite um nome e selecione um branch para fazer o build. O novo webhook ser\xe1 exibido na interface do Amplify. Copie o URL porque vamos precisar dele no GitHub.\\n\\n<br/>\\n\\n![Amplify Incming Webhooks](./amplify_incoming_webhooks.webp)\\n\\n<br/>\\n\\nAgora volte para o repo no GitHub, selecione Configura\xe7\xf5es > Webhooks e clique no bot\xe3o Add webhook (Adicionar webhook).\\n\\n<br/>\\n\\n![Adding GitHub Webhooks](./github_webhooks.webp)\\n\\nAcabou, finalmente.\\n\\n### Limita\xe7\xf5es do webhook\\n\\nSe voc\xea usar o webhook, lembre-se de que:\\n\\n- Se precisar conectar v\xe1rios branches ao Amplify, voc\xea vai precisar de um webhook no Amplify para cada branch, e vai precisar adicionar cada webhook ao GitHub, um por um. Se bater a tenta\xe7\xe3o de fazer um script, converse com a galera que faz admin do Github na sua empresa e tenta aprovar o app Amplify. Ningu\xe9m merece viver na gambiarra.  \\n- Qualquer git push vai espoletar (trigger) o webhook em cada deploy no Amplify. Em outras palavras, se voc\xea tiver as branches \u201cmain\u201d, \u201crelease\u201d, \u201cdev\u201d, \u201cfeature/a\u201d e \u201cfeature/b\u201d, toda vez que algu\xe9m fizer um push em \u201cdev\u201d, a pipeline vai espoletar em todas as cinco branches.\\n\\nEspero ter sido \xfatil, at\xe9 mais!"}]}}')}}]);