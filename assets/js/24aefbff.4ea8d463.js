"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7933],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>m});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function r(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var s=a.createContext({}),u=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},p=function(e){var t=u(e.components);return a.createElement(s.Provider,{value:t},e.children)},c="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,o=e.originalType,s=e.parentName,p=r(e,["components","mdxType","originalType","parentName"]),c=u(n),d=i,m=c["".concat(s,".").concat(d)]||c[d]||h[d]||o;return n?a.createElement(m,l(l({ref:t},p),{},{components:n})):a.createElement(m,l({ref:t},p))}));function m(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=n.length,l=new Array(o);l[0]=d;var r={};for(var s in t)hasOwnProperty.call(t,s)&&(r[s]=t[s]);r.originalType=e,r[c]="string"==typeof e?e:i,l[1]=r;for(var u=2;u<o;u++)l[u]=n[u];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},6190:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>u});var a=n(7462),i=(n(7294),n(3905));const o={slug:"github-actions-data-flow",title:"GitHub Actions: Data Flow & Data Persistence",authors:"manu",tags:["github actions","ci/cd","pipeline"]},l=void 0,r={permalink:"/blog/tech/github-actions-data-flow",source:"@site/tech/2023-10-31-github-actions-data-flow/index.md",title:"GitHub Actions: Data Flow & Data Persistence",description:"In Github Actions, by default, data is not inherently persistent or available to the whole pipeline. Every step has is its own process, every job has its own runner. By default, whatever data emerges in a job, ends with it.",date:"2023-10-31T00:00:00.000Z",formattedDate:"October 31, 2023",tags:[{label:"github actions",permalink:"/blog/tech/tags/github-actions"},{label:"ci/cd",permalink:"/blog/tech/tags/ci-cd"},{label:"pipeline",permalink:"/blog/tech/tags/pipeline"}],readingTime:8.785,hasTruncateMarker:!0,authors:[{name:"Manu Magalh\xe3es",title:"DevSecOps Engineer",url:"https://github.com/magmanu",imageURL:"https://github.com/magmanu.png",key:"manu"}],frontMatter:{slug:"github-actions-data-flow",title:"GitHub Actions: Data Flow & Data Persistence",authors:"manu",tags:["github actions","ci/cd","pipeline"]},nextItem:{title:"Generating Dynamic JSON in Terraform",permalink:"/blog/tech/dynamic-json-in-terraform"}},s={authorsImageUrls:[void 0]},u=[{value:"Using <code>env</code>",id:"using-env",level:2},{value:"Debugging tip",id:"debugging-tip",level:4},{value:"Using <code>outputs</code>",id:"using-outputs",level:2},{value:"Using artefacts",id:"using-artefacts",level:2},{value:"Uploading artefacts",id:"uploading-artefacts",level:3},{value:"Downloading artefacts",id:"downloading-artefacts",level:3},{value:"Deleting artefacts",id:"deleting-artefacts",level:3},{value:"Using cache",id:"using-cache",level:2}],p={toc:u},c="wrapper";function h(e){let{components:t,...n}=e;return(0,i.kt)(c,(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"In Github Actions, by default, data is not inherently persistent or available to the whole pipeline. Every step has is its own process, every job has its own runner. By default, whatever data emerges in a job, ends with it."),(0,i.kt)("p",null,"How do we pass data from one process to the other, or save it for the next process?"),(0,i.kt)("p",null,"A short sweet answer:"),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Strategy"),(0,i.kt)("th",{parentName:"tr",align:null},"Data"),(0,i.kt)("th",{parentName:"tr",align:null},"Scope"),(0,i.kt)("th",{parentName:"tr",align:null},"Persistence"),(0,i.kt)("th",{parentName:"tr",align:null},"Explanation"),(0,i.kt)("th",{parentName:"tr",align:null},"Example"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"env")),(0,i.kt)("td",{parentName:"tr",align:null},"Values"),(0,i.kt)("td",{parentName:"tr",align:null},"Job (internal)"),(0,i.kt)("td",{parentName:"tr",align:null},"Ephemeral"),(0,i.kt)("td",{parentName:"tr",align:null},"Propagates ",(0,i.kt)("em",{parentName:"td"},"data")," ",(0,i.kt)("br",null)," between ",(0,i.kt)("em",{parentName:"td"},"steps")," ",(0,i.kt)("br",null),"  in the same ",(0,i.kt)("em",{parentName:"td"},"job")),(0,i.kt)("td",{parentName:"tr",align:null},"Pass a boolean to control whether the next step should run")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"outputs")),(0,i.kt)("td",{parentName:"tr",align:null},"Values"),(0,i.kt)("td",{parentName:"tr",align:null},"Workflow (internal)"),(0,i.kt)("td",{parentName:"tr",align:null},"Ephemeral"),(0,i.kt)("td",{parentName:"tr",align:null},"Propagates ",(0,i.kt)("em",{parentName:"td"},"data")," ",(0,i.kt)("br",null)," between ",(0,i.kt)("em",{parentName:"td"},"jobs/steps")," ",(0,i.kt)("br",null),"  in the same ",(0,i.kt)("em",{parentName:"td"},"workflow")),(0,i.kt)("td",{parentName:"tr",align:null},"Pass a deployment id to the next job")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"artefacts"),(0,i.kt)("td",{parentName:"tr",align:null},"Files"),(0,i.kt)("td",{parentName:"tr",align:null},"Workflow (internal & external)"),(0,i.kt)("td",{parentName:"tr",align:null},"Persistent"),(0,i.kt)("td",{parentName:"tr",align:null},"Propagates ",(0,i.kt)("em",{parentName:"td"},"files")," ",(0,i.kt)("br",null)," between ",(0,i.kt)("em",{parentName:"td"},"jobs/workflows")),(0,i.kt)("td",{parentName:"tr",align:null},"Pass the project build to different test jobs running in parallel  ",(0,i.kt)("br",null),(0,i.kt)("br",null)," ",(0,i.kt)("em",{parentName:"td"},"Intended for frequently changing data. Files are available for download after the workflow finishes."))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"cache"),(0,i.kt)("td",{parentName:"tr",align:null},"Files"),(0,i.kt)("td",{parentName:"tr",align:null},"Workflow (internal & external)"),(0,i.kt)("td",{parentName:"tr",align:null},"Persistent"),(0,i.kt)("td",{parentName:"tr",align:null},"Propagates ",(0,i.kt)("em",{parentName:"td"},"files")," ",(0,i.kt)("br",null)," inside and between ",(0,i.kt)("em",{parentName:"td"},"workflows")," ",(0,i.kt)("br",null),"  in the same ",(0,i.kt)("em",{parentName:"td"},"repository")),(0,i.kt)("td",{parentName:"tr",align:null},"Cache npm packages for use in different workflow runs. ",(0,i.kt)("br",null),(0,i.kt)("br",null)," ",(0,i.kt)("em",{parentName:"td"},"Intended for files that don't change much."))))),(0,i.kt)("p",null,"For a completer answer: read on.",(0,i.kt)("br",{parentName:"p"}),"\n","All the workflow examples in this article ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/magmanu/blog/tree/main/demos/github-actions-data-flow"},"can be found as files here"),", along with a copy of the respective redacted logs."),(0,i.kt)("h2",{id:"using-env"},"Using ",(0,i.kt)("inlineCode",{parentName:"h2"},"env")),(0,i.kt)("p",null,"It's pretty simple to create a data flow between steps: define a key-value pair and write it to the ",(0,i.kt)("inlineCode",{parentName:"p"},"GITHUB_ENV")," environment file, using the appropriate syntax for your shell. See examples below in bash and python:"),(0,i.kt)("details",null,(0,i.kt)("summary",null,"Show code"),(0,i.kt)("div",null,(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml",metastring:'title="/.github/workflows/using_env.yaml"',title:'"/.github/workflows/using_env.yaml"'},'    steps:\n      - name: Two ways to set environment variable with sh\n      # Warning: in this step, the input is not sanitized or validated\n        shell: bash\n        run: |\n          # No print to the logs.\n          random_wiki_article_1=$(curl -L -X GET "https://en.wikipedia.org/api/rest_v1/page/random/summary" | jq .title)\n          echo "$random_wiki_article_1"\n          echo "ARTICLE_1=$random_wiki_article_1" >> "$GITHUB_ENV"\n          # \ud83d\udc09 Print the variable in the logs: only for non-senstive data!\n          random_wiki_article_2=$(curl -L -X GET "https://en.wikipedia.org/api/rest_v1/page/random/summary" | jq .title)\n          echo "ARTICLE_2=$random_wiki_article_2" | tee -a "$GITHUB_ENV"\n\n      - name: Set environment variable with python\n        shell: python\n        # if using "write", use \\n when creating multiple vars\n        # with "print", you can omit \\n\n        run: |\n          from os import environ as env\n          with open(env.get(\'GITHUB_ENV\', None), \'a\') as ghenv:\n            ghenv.write("SUBJECT=Sun\\n")\n            print("STATE=radiant", file=ghenv)\n            print("TIME=today", file=ghenv)\n          \n      - name: \ud83d\udee1\ufe0f Retrieving values securely\n        # observe that ARTICLE_1 was not sanitized or validated, so it\'s vulnerable to injection attacks.\n        # The approach below prevents the issue by setting env.ARTICLE_1 as an argument to the script.\n        # It also gives you the chance to rename the variables\n        env:\n          WHO: ${{ env.SUBJECT }}\n          WHAT: ${{ env.ARTICLE_1 }}\n          WHEN: ${{ env.TIME }}\n        run: |\n          echo "$WHO read about $WHAT $WHEN."\n        \n      - name: \ud83d\udc09 Retrieving values in a potentially vulnerable way\n        # This approach is vulnerable to injection attacks!\n        # Only use it if you have control over the input\n        shell: bash\n        run: |\n          echo "${{ env.SUBJECT }} is ${{ env.STATE }} ${{ env.TIME }}."\n')))),(0,i.kt)("h4",{id:"debugging-tip"},"Debugging tip"),(0,i.kt)("p",null,"To list all the environment variables available in a job, add this tiny step:"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"- run: env")),(0,i.kt)("h2",{id:"using-outputs"},"Using ",(0,i.kt)("inlineCode",{parentName:"h2"},"outputs")),(0,i.kt)("p",null,"Outputs are available to all steps in the same job, and to any subsequent job that ",(0,i.kt)("inlineCode",{parentName:"p"},"needs")," it.",(0,i.kt)("br",{parentName:"p"}),"\n","The output is always an unicode ",(0,i.kt)("strong",{parentName:"p"},"string"),".  "),(0,i.kt)("p",null,"And obviously, jobs that depend on an ",(0,i.kt)("inlineCode",{parentName:"p"},"output")," will not run in parallel with the job that produces the output."),(0,i.kt)("details",null,(0,i.kt)("summary",null,"Show code"),(0,i.kt)("div",null,(0,i.kt)("p",null,"For simplicity, I show how to set the output in bash, but you can use any shell of your choice.  "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml",metastring:'title="/.github/workflows/outputs-for-different-job.yaml"',title:'"/.github/workflows/outputs-for-different-job.yaml"'},'jobs:\n  setting-outputs:\n    runs-on: ubuntu-latest\n    // highlight-start\n    outputs:  # Required: name the output in the job level so it\'s available to other jobs\n      person_name: ${{ steps.use-hardcoded-value.outputs.NAME }}\n      location: ${{ steps.use-dynamic-value.outputs.LOCATION }}\n    // highlight-end\n    steps:\n      - id: use-hardcoded-value\n        run: |\n          // highlight-next-line\n          echo "NAME=Marcela" >> "$GITHUB_OUTPUT"\n      \n      - id: use-dynamic-value\n        # note the use of jq -c to get the value as a single line\n        run: |\n          location=$(curl -H "Accept: application/json" https://randomuser.me/api/ | jq -c .results[].location)\n          // highlight-next-line\n          echo "LOCATION=$location" > "$GITHUB_OUTPUT"\n\n  retrieving-outputs:\n    runs-on: ubuntu-latest\n    needs: setting-outputs\n    steps:\n      - name: Greet to location\n        run: |\n          COUNTRY=$(echo $GEODATA | jq -r . | jq .country)\n          echo "Hello $NAME, welcome to $COUNTRY!"\n         // highlight-start\n        env:\n          NAME: ${{needs.setting-outputs.outputs.person_name}}\n          GEODATA: ${{ needs.setting-outputs.outputs.location }}\n        // highlight-end\n')))),(0,i.kt)("p",null,"Even though it's recommended to use ",(0,i.kt)("inlineCode",{parentName:"p"},"env")," to pass data between steps, ",(0,i.kt)("inlineCode",{parentName:"p"},"outputs")," can be used for that purpose as well. This is useful when a value is required both in the current job and in subsequent jobs.  "),(0,i.kt)("details",null,(0,i.kt)("summary",null,"Show code"),(0,i.kt)("div",null,(0,i.kt)("p",null,"The previous example showed how to use outputs in different jobs.",(0,i.kt)("br",{parentName:"p"}),"\n","To use an output the same job, simply add the code in the highlighted section."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml",metastring:'title="/.github/workflows/outputs-for-same-job.yaml"',title:'"/.github/workflows/outputs-for-same-job.yaml"'},'jobs:\n  extract:\n    runs-on: ubuntu-latest\n    outputs:\n      person_name: ${{ steps.generate-hardcoded-value.outputs.name }}\n      location: ${{ steps.enerate-dynamic-value.outputs.location }}\n        steps:\n      - id: generate-hardcoded-value\n        run: |\n          echo "NAME=Marcela" >> "$GITHUB_OUTPUT"\n      - id: generate-dynamic-value\n        run: |\n          location=$(curl -H "Accept: application/json" https://randomuser.me/api/ | jq .results[].location | jq @json) \n          echo "LOCATION=$location" >> "$GITHUB_OUTPUT"\n      // highlight-start\n      - name: Consume output in same job\n        run: |\n          echo "$PERSON, you\'re in $GEODATA, so we\'ve updated your timezone to GMT$OFFSET."\n        env:\n          PERSON: ${{ steps.use-hardcoded-value.outputs.NAME }}\n          # use fromJSON() when filtering the output value at the env level\n          # See more about object filtering in \n          # https://docs.github.com/en/actions/learn-github-actions/expressions#object-filters\n          GEODATA: ${{ fromJSON(steps.use-dynamic-value.outputs.LOCATION).country }}\n          OFFSET: ${{ fromJSON(steps.use-dynamic-value.outputs.LOCATION).timezone.offset }}\n      // highlight-end\n\n    (...)\n')))),(0,i.kt)("admonition",{title:"Helpful debugging info",type:"info"},(0,i.kt)("ul",{parentName:"admonition"},(0,i.kt)("li",{parentName:"ul"},"An individual output should be 1MB max. "),(0,i.kt)("li",{parentName:"ul"},"All outputs combined should not exceed 50MB."))),(0,i.kt)("br",null),(0,i.kt)("admonition",{title:"Real life XP",type:"tip"},(0,i.kt)("p",{parentName:"admonition"},(0,i.kt)("inlineCode",{parentName:"p"},"GITHUB_OUTPUT")," expects a one-line string.",(0,i.kt)("br",{parentName:"p"}),"\n","If you need a multiline output, assign it to a variable and write to the output as follows:"),(0,i.kt)("pre",{parentName:"admonition"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'echo "PAYLOAD_NAME<<EOF"$\'\\n\'"$payload_var"$\'\\n\'EOF >> "$GITHUB_OUTPUT".\n'))),(0,i.kt)("h2",{id:"using-artefacts"},"Using artefacts"),(0,i.kt)("p",null,'From the docs: "',(0,i.kt)("em",{parentName:"p"},"Use artefacts when you want to save files produced by a job to view after a workflow run has ended, such as built binaries or build logs"),'."'),(0,i.kt)("h3",{id:"uploading-artefacts"},"Uploading artefacts"),(0,i.kt)("p",null,"You can:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"select one or multiple files to be bundled as an artifact.  "),(0,i.kt)("li",{parentName:"ul"},"use wildcards, multiple paths and exclusion patterns in the usual GitHub Actions syntax.  "),(0,i.kt)("li",{parentName:"ul"},"set a retention period for the artefact.")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml",metastring:'title="/.github/workflows/handle-artefacts.yaml"',title:'"/.github/workflows/handle-artefacts.yaml"'},"jobs:\n  upload:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Upload log files\n        uses: actions/upload-artifact@v4\n        with:\n          name: all-logs      # artefact name\n          path: |             # path to files to be included in the artifact.\n            **/log*.txt       # relative paths are rooted against $GITHUB_WORKSPACE\n          retention-days: 1\n          if-no-files-found: error # force step to fail if the content for the artefact is not found\n")),(0,i.kt)("p",null,"Note that maximum retention period ",(0,i.kt)("a",{parentName:"p",href:"https://docs.github.com/en/actions/learn-github-actions/usage-limits-billing-and-administration#artifact-and-log-retention-policy"},"can be defined at repo, organisation, or enterprise level"),". There's a max of 90 days for public repos and 400 days for private repos. If you lower the retention period, you'll have more non-billed space ;) "),(0,i.kt)("h3",{id:"downloading-artefacts"},"Downloading artefacts"),(0,i.kt)("p",null,"To retrieve the artefact, you can use:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"the ",(0,i.kt)("a",{parentName:"li",href:"https://docs.github.com/en/actions/managing-workflow-runs/downloading-workflow-artifacts"},"Github UI")),(0,i.kt)("li",{parentName:"ul"},"the ",(0,i.kt)("a",{parentName:"li",href:"https://docs.github.com/en/rest/actions/artifacts?apiVersion=2022-11-28#download-an-artifact"},"Github API")),(0,i.kt)("li",{parentName:"ul"},"the ",(0,i.kt)("a",{parentName:"li",href:"https://docs.github.com/en/actions/managing-workflow-runs/downloading-workflow-artifacts?tool=cli"},(0,i.kt)("inlineCode",{parentName:"a"},"gh")," cli")),(0,i.kt)("li",{parentName:"ul"},"the official ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/marketplace/actions/download-a-build-artifact"},(0,i.kt)("inlineCode",{parentName:"a"},"actions/download-artifact"))," action, if you need to retrieve artifacts programmatically. From ",(0,i.kt)("inlineCode",{parentName:"li"},"v4"),", the action allows you to download artefacts from a different workflows or repos, as long as you provide a token. (\ud83d\udee1\ufe0f: it's recommended to use a GitHub App rather than a PAT for professional projects.)")),(0,i.kt)("p",null,"Let's see how to retrieve the artefact we created in the previous example using ",(0,i.kt)("inlineCode",{parentName:"p"},"actions/download-artifact"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml",metastring:'title="/.github/workflows/handle-artefacts.yaml"',title:'"/.github/workflows/handle-artefacts.yaml"'},'download:\n    runs-on: ubuntu-latest\n    needs: upload\n    steps:\n      - name: Download log files\n        id: download-artifacts\n        uses: actions/download-artifact@v4\n        with:\n          name: all-logs  # note it uses the name defined in the upload step\n        \n      - name: Pass artifact path to python\n        shell: python\n        run: |\n          import os\n          from glob import glob\n          artifact_path = os.environ.get("ARTIFACT_PATH", "")\n          glob_list = glob(artifact_path + "/*.txt")\n          for filename in glob_list:\n              with open(filename, "r", encoding="UTF-8") as f:\n                  content = f.read()\n                  print(content)\n        env:\n          ARTIFACT_PATH: ${{ steps.download-artifacts.outputs.download-path }}\n')),(0,i.kt)("p",null,"All the zipping and unzipping of the artifacts is automatically handled by the actions."),(0,i.kt)("h3",{id:"deleting-artefacts"},"Deleting artefacts"),(0,i.kt)("p",null,"To delete an artefact, you can:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"use the ",(0,i.kt)("a",{parentName:"li",href:"https://docs.github.com/en/actions/managing-workflow-runs/removing-workflow-artifacts"},"Github UI")),(0,i.kt)("li",{parentName:"ul"},"use the ",(0,i.kt)("a",{parentName:"li",href:"https://docs.github.com/en/rest/reference/actions#delete-an-artifact"},"Github API")),(0,i.kt)("li",{parentName:"ul"},"write a ",(0,i.kt)("a",{parentName:"li",href:"https://gist.github.com/qwe321qwe321qwe321/efae4569576006624c34f23b2dd76a58"},"custom script using the Github API")," or using a ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/GeekyEggo/delete-artifact"},"community action"),".")),(0,i.kt)("h2",{id:"using-cache"},"Using cache"),(0,i.kt)("admonition",{title:"\ud83d\udc09 Security warning",type:"danger"},(0,i.kt)("p",{parentName:"admonition"},"Do not store sensitive information in the cache (beware of configuration files containing secrets), as the cache is accessible to anyone who can create a PR on the repository, even on forks.")),(0,i.kt)("p",null,"This post is already too long, so here's what you need to know about caching:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"If you\u2019re using self-hosted runners, the option to self-store the cache is only available in Enterprise plans.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"The cache action requires a ",(0,i.kt)("inlineCode",{parentName:"p"},"path")," to the cache and a ",(0,i.kt)("inlineCode",{parentName:"p"},"key"),". The ",(0,i.kt)("inlineCode",{parentName:"p"},"key")," is used to retrieve the cache and to recreate it next time. ")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"When the job finishes, the action will automatically inject a post cache step that updates the cache if new dependencies were installed.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"This action manages the cache centrally. This means that the cache is available (and updatable) to all jobs in the same repository, and it's also available to other workflows.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Read more about ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/actions/cache/blob/main/caching-strategies.md"},"caching strategies here"),"."))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml",metastring:'title="/.github/workflows/cache.yaml"',title:'"/.github/workflows/cache.yaml"'},"jobs:\n  cache:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.12'\n          cache: 'pip'\n          cache-dependency-path: |\n            **/requirements.txt\n      \n      - name: Get pip cache dir\n        id: pip-cache\n        run: |\n          echo \"dir=$(pip cache dir)\" >> $GITHUB_OUTPUT\n\n      - name: Handle cache for Python dependencies\n        uses: actions/cache@v3\n        id: cache\n        with:\n          path: ${{ steps.pip-cache.outputs.dir }}\n          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}\n        \n      - name: Install dependencies if not found in cache\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: pip install -r requirements.txt\n")),(0,i.kt)("p",null,"If you want to see the proof of the pudding, check out the saved logs:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://raw.githubusercontent.com/magmanu/blog/main/demos/github-actions-data-flow/31_data_flow_cache_set-cache.txt"},"set cache logs"),": first run, there's no cache so it's set"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://raw.githubusercontent.com/magmanu/blog/main/demos/github-actions-data-flow/32_data_flow_cache_use-cache.txt"},"use cache logs"),": second run, the cache has a hit and is used"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://raw.githubusercontent.com/magmanu/blog/main/demos/github-actions-data-flow/33_data_flow_cache_update-cache.txt"},"update cache logs"),": the requirements.txt file changed, so the cache is a miss. The dependencies are reinstalled and the cache is updated.")),(0,i.kt)("p",null,"Cool note: Have you noted the ",(0,i.kt)("inlineCode",{parentName:"p"},"hashFiles")," function used in the key above?",(0,i.kt)("br",{parentName:"p"}),"\n","This is a function provided by GitHub Actions to create a unique hash value based on a file path. If the hash value doesn't match, it means that the dependencies have changed and the cache is not used. Instead, the dependencias are reinstalled and the cache is updated on a post-cache job."),(0,i.kt)("p",null,"Happy pipelining :)"))}h.isMDXComponent=!0}}]);